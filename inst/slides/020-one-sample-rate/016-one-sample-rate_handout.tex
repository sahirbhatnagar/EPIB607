\documentclass[10pt,handout]{beamer}\usepackage[]{graphicx}\usepackage[]{color}
% maxwidth is the original width if it is less than linewidth
% otherwise use linewidth (to make sure the graphics do not exceed the margin)
\makeatletter
\def\maxwidth{ %
  \ifdim\Gin@nat@width>\linewidth
    \linewidth
  \else
    \Gin@nat@width
  \fi
}
\makeatother

\definecolor{fgcolor}{rgb}{0.345, 0.345, 0.345}
\newcommand{\hlnum}[1]{\textcolor[rgb]{0.686,0.059,0.569}{#1}}%
\newcommand{\hlstr}[1]{\textcolor[rgb]{0.192,0.494,0.8}{#1}}%
\newcommand{\hlcom}[1]{\textcolor[rgb]{0.678,0.584,0.686}{\textit{#1}}}%
\newcommand{\hlopt}[1]{\textcolor[rgb]{0,0,0}{#1}}%
\newcommand{\hlstd}[1]{\textcolor[rgb]{0.345,0.345,0.345}{#1}}%
\newcommand{\hlkwa}[1]{\textcolor[rgb]{0.161,0.373,0.58}{\textbf{#1}}}%
\newcommand{\hlkwb}[1]{\textcolor[rgb]{0.69,0.353,0.396}{#1}}%
\newcommand{\hlkwc}[1]{\textcolor[rgb]{0.333,0.667,0.333}{#1}}%
\newcommand{\hlkwd}[1]{\textcolor[rgb]{0.737,0.353,0.396}{\textbf{#1}}}%
\let\hlipl\hlkwb

\usepackage{framed}
\makeatletter
\newenvironment{kframe}{%
 \def\at@end@of@kframe{}%
 \ifinner\ifhmode%
  \def\at@end@of@kframe{\end{minipage}}%
  \begin{minipage}{\columnwidth}%
 \fi\fi%
 \def\FrameCommand##1{\hskip\@totalleftmargin \hskip-\fboxsep
 \colorbox{shadecolor}{##1}\hskip-\fboxsep
     % There is no \\@totalrightmargin, so:
     \hskip-\linewidth \hskip-\@totalleftmargin \hskip\columnwidth}%
 \MakeFramed {\advance\hsize-\width
   \@totalleftmargin\z@ \linewidth\hsize
   \@setminipage}}%
 {\par\unskip\endMakeFramed%
 \at@end@of@kframe}
\makeatother

\definecolor{shadecolor}{rgb}{.97, .97, .97}
\definecolor{messagecolor}{rgb}{0, 0, 0}
\definecolor{warningcolor}{rgb}{1, 0, 1}
\definecolor{errorcolor}{rgb}{1, 0, 0}
\newenvironment{knitrout}{}{} % an empty environment to be redefined in TeX

\usepackage{alltt}


%\input{slides_header.tex}
\input{/home/sahir/git_repositories/EPIB607/slides/slides_header2.tex}
\graphicspath{{/home/sahir/git_repositories/EPIB607/slides/figure/}}

%\let\oldShaded\Shaded
%\let\endoldShaded\endShaded
%\renewenvironment{Shaded}{\footnotesize\oldShaded}{\endoldShaded}
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\begin{document}

	

%\title{Introduction to Regression Trees}
%\author{Sahir Bhatnagar \inst{1}}
%\author[shortname]{Sahir Rai Bhatnagar, PhD Candidate (Biostatistics) }
%\institute[shortinst]{Department of Epidemiology, Biostatistics and Occupational Health}

	\title{016 - Inference about a Population Rate ($\lambda$)}
\author{EPIB 607 - FALL 2020}
\institute{
	Sahir Rai Bhatnagar\\
	Department of Epidemiology, Biostatistics, and Occupational Health\\
	McGill University\\
	
	\vspace{0.1 in}
	
	\texttt{sahir.bhatnagar@mcgill.ca}\\
	%\texttt{\url{https://sahirbhatnagar.com/EPIB607/}}
}

\date{slides compiled on \today}

\maketitle

\begin{frame}[fragile,plain]
\begin{knitrout}\tiny
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}

{\centering \includegraphics[width=\maxwidth]{figure/unnamed-chunk-1-1} 

}



\end{knitrout}
\end{frame}


\section{Motivating example}

\begin{frame}{Motivating example: HPV-16 Vaccine}
	
	\includegraphics[scale=0.35]{nejm_hpv.png}
	
\end{frame}


\begin{frame}{Motivating example: HPV-16 Vaccine}
	\footnotesize
	\begin{itemize}
		\item \textbf{Background}: $\approx$ 20\% of adults become infected with human papillomavirus type 16 (HPV-16), someof which progress to anogenital cancer. 
		\pause
		\item \textbf{Methods}: 
		\begin{itemize}
			\footnotesize
			\item Randomly assigned 2392 young women (females age 16-23) to receive three doses of placebo or HPV-16 virus-like-particle vaccine (40 Î¼g per dose), given at day 0, month 2, and month 6. 
			\item Genital samples to test for HPV-16 DNA were obtained at enrollment,	one month after the third vaccination, and every six months thereafter. 
			\item The primary end point was persistent HPV-16 infection, defined as the detection of HPV-16 DNA in samples obtained at two or more visits. 
		\end{itemize}
		\pause 
		\item \textbf{Results}: \begin{itemize}
			\footnotesize
			\item Median follow-up time of 17.4 months
			\item Incidence of persistent HPV-16 infection: \begin{itemize}
				\footnotesize
				\item Placebo: 3.8 per 100 woman-years at risk
				\item Vaccine: 0 per 100 woman-years at risk
			\end{itemize}
		\end{itemize}
	\end{itemize}
\end{frame}


\begin{frame}{Table 3}
	\includegraphics[scale=0.3]{nejm_tab3.png}
	
	\vspace{0.5in}
	\alert{Question}: For Primary and Secondary per-protocol efficacy analysis, calculate a 95\% CI of infection rate per 100 woman-years at risk for vaccine and placebo group.
	
\end{frame}


\begin{frame}[fragile]{Normal Approximation Based CI for the Count}
	
	\underline{Primary analysis:}
	\vspace{0.1in}
\begin{knitrout}\tiny
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlcom{# Vaccine group}
\hlkwd{qnorm}\hlstd{(}\hlkwc{p} \hlstd{=} \hlkwd{c}\hlstd{(}\hlnum{0.025}\hlstd{,} \hlnum{0.975}\hlstd{),} \hlkwc{mean} \hlstd{=} \hlnum{0}\hlstd{,} \hlkwc{sd} \hlstd{=} \hlkwd{sqrt}\hlstd{(}\hlnum{0}\hlstd{))}
\end{alltt}
\begin{verbatim}
## [1] 0 0
\end{verbatim}
\begin{alltt}
\hlcom{# Placebo}
\hlkwd{qnorm}\hlstd{(}\hlkwc{p} \hlstd{=} \hlkwd{c}\hlstd{(}\hlnum{0.025}\hlstd{,} \hlnum{0.975}\hlstd{),} \hlkwc{mean} \hlstd{=} \hlnum{41}\hlstd{,} \hlkwc{sd} \hlstd{=} \hlkwd{sqrt}\hlstd{(}\hlnum{41}\hlstd{))}
\end{alltt}
\begin{verbatim}
## [1] 28 54
\end{verbatim}
\end{kframe}
\end{knitrout}
	
\end{frame}

\begin{frame}[fragile]{Normal Approximation Based CI for the Count}
	
	\underline{Secondary analysis:}
	\vspace{0.1in}
\begin{knitrout}\tiny
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlcom{# Vaccine group}
\hlkwd{qnorm}\hlstd{(}\hlkwc{p} \hlstd{=} \hlkwd{c}\hlstd{(}\hlnum{0.025}\hlstd{,} \hlnum{0.975}\hlstd{),} \hlkwc{mean} \hlstd{=} \hlnum{6}\hlstd{,} \hlkwc{sd} \hlstd{=} \hlkwd{sqrt}\hlstd{(}\hlnum{6}\hlstd{))}
\end{alltt}
\begin{verbatim}
## [1]  1.2 10.8
\end{verbatim}
\begin{alltt}
\hlcom{# Placebo}
\hlkwd{qnorm}\hlstd{(}\hlkwc{p} \hlstd{=} \hlkwd{c}\hlstd{(}\hlnum{0.025}\hlstd{,} \hlnum{0.975}\hlstd{),} \hlkwc{mean} \hlstd{=} \hlnum{68}\hlstd{,} \hlkwc{sd} \hlstd{=} \hlkwd{sqrt}\hlstd{(}\hlnum{68}\hlstd{))}
\end{alltt}
\begin{verbatim}
## [1] 52 84
\end{verbatim}
\end{kframe}
\end{knitrout}
	
\end{frame}


\begin{frame}[fragile]{Coverage Probability of Normal Approx. - Truth is Poisson($\mu=6$)}
	
\begin{knitrout}\tiny
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}

{\centering \includegraphics[width=\maxwidth]{figure/unnamed-chunk-4-1} 

}



\end{knitrout}
	
\end{frame}



\begin{frame}[fragile]{Coverage Probability of Exact Method - Truth is Poisson($\mu=6$)}
	
\begin{knitrout}\tiny
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}

{\centering \includegraphics[width=\maxwidth]{figure/unnamed-chunk-5-1} 

}



\end{knitrout}
	
\end{frame}



\begin{frame}[fragile]{Coverage Probability Normal Approx. - Truth is Poisson($\mu=68$)}
	
\begin{knitrout}\tiny
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}

{\centering \includegraphics[width=\maxwidth]{figure/unnamed-chunk-6-1} 

}



\end{knitrout}
	
\end{frame}



\begin{frame}[fragile]{Coverage Probability Exact Method - Truth is Poisson($\mu=68$)}
	
\begin{knitrout}\tiny
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}

{\centering \includegraphics[width=\maxwidth]{figure/unnamed-chunk-7-1} 

}



\end{knitrout}
	
\end{frame}



%\begin{frame}[fragile]{Motivating example: Demand for medical care}

%\vspace*{-0.2in}




%\end{frame}

\begin{comment}
\begin{frame}{Some observations about the previous plot}

\begin{itemize}
\setlength\itemsep{1em}
\item Discrete outcome $\to$ 0, 1, 2, 3, ... visits \pause 
\item There are rare events, e.g. 1 individual with 89 visits \pause 
\item The data are far from normally distributed \pause
\item Can theoretically go on forever
\end{itemize}

\end{frame}


\begin{frame}{The Poisson Distribution}


\begin{itemize}
\setlength\itemsep{1em}
\item The binomial distribution was derived by starting with an experiment consisting of trials or draws and applying the laws of probability to various outcomes of the experiment. \pause 
\item There is no simple experiment on which the Poisson distribution is based, although we will shortly describe how it can be obtained by certain limiting operations.
\end{itemize}

\end{frame}
\end{comment}


\section{Poisson Model for Sampling Variability of a Count in a Given Amount of ``Experience''}

\begin{frame}
	\frametitle{The Poisson Distribution}
	
	\begin{itemize}
		\small
		\setlength\itemsep{1em}
		\item The (infinite number of) probabilities $P_{0}, P_{1}, ..., P_{y}, ..., $ of observing 
		$Y = 0, 1, 2, \dots , y, \dots $ events in a given amount of ``experience.'' 
		
		\item These probabilities, $P(Y = k) \to$ \texttt{dpois()}, are governed by a single parameter, the mean $E[Y] = \mu$ which represents the expected \textbf{number} of events in the amount of experience actually studied. 
		
		\item We say that a random variable $Y \sim \textrm{Poisson}(\mu)$ distribution if 
		
		\[ P(Y=k) = \frac{\mu^k}{k!}e^{-\mu}, \quad k = 0, 1, 2, \ldots\]
		\pause 
		
		\item Note: in \texttt{dpois()} $\mu$ is referred to as \texttt{lambda}
		
		\item Note the distinction between $\mu$ and $\lambda$
		\begin{itemize}
			\item $\mu$: expected \textbf{number} of events
			\item $\lambda$: \textbf{rate} parameter
		\end{itemize}
	\end{itemize}
\end{frame}




\begin{frame}[fragile]{The probability mass function for $\mu=6$}
	
\begin{knitrout}\tiny
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{dpois}\hlstd{(}\hlkwc{x} \hlstd{=} \hlnum{0}\hlopt{:}\hlnum{15}\hlstd{,} \hlkwc{lambda} \hlstd{=} \hlnum{6}\hlstd{)}
\end{alltt}
\end{kframe}
\end{knitrout}
	
	\vspace*{-0.5in}
	
\begin{knitrout}\tiny
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}

{\centering \includegraphics[width=\maxwidth]{figure/unnamed-chunk-10-1} 

}



\end{knitrout}
	
\end{frame}


\begin{frame}[fragile]{The probability mass function}
	
\begin{knitrout}\tiny
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}

{\centering \includegraphics[width=\maxwidth]{figure/unnamed-chunk-11-1} 

}



\end{knitrout}
	
\end{frame}


\begin{frame}
	\frametitle{The Poisson Distribution: what it is, and features}
	
	\begin{itemize}
		\setlength\itemsep{2em}
		\item  $\sigma^2_Y =  \mu \ \to \ \ \sigma_Y =  \sqrt{\mu}.$ \pause
		\item  Approximated by $\mathcal{N}(\mu, \sqrt{\mu})$ when $\mu >> 10$ \pause 
		\item Open-ended (unlike Binomial), but in practice, has finite range. 
		
		\item Poisson data sometimes called ``numerator only'':  (unlike Binomial) may not ``see'' or  count ``non-events''
	\end{itemize}
\end{frame}



\begin{frame}{Normal approximation to Poisson is the CLT in action}
	\includegraphics[width=\linewidth]{hist-pois-1} 
\end{frame}	

%\end{document}


\begin{frame}
	\frametitle{How it arises}
	
	
	\begin{itemize}
		\setlength\itemsep{1em}
		\item  Count of events or items that \underline{occur randomly}, with \underline{low homogeneous intensity}, in time, space, or `item'-time (e.g. person--time). 
		\item Binomial($n,\pi$) when $n \rightarrow \infty\textrm{ and } \pi \rightarrow 0,$ but $n \times \pi = \mu$ is finite.
		\item $Y\sim Poisson(\mu_Y)$ if time ($T$) between events follows an $T \sim \textrm{Exponential}(\mu_{T} = 1/\mu_{Y}).$ 
		{ \scriptsize   \url{http://www.epi.mcgill.ca/hanley/bios601/Intensity-Rate/Randomness_poisson.pdf}} 
		\item  As sum of $\ge 2$  \textit{independent} Poisson random variables, 
		with same \textbf{or different} $\mu$'s: \newline 
		$Y_{1} \sim \textrm{Poisson}(\mu_{1}) \: \:   
		Y_{2} \sim \textrm{Poisson}(\mu_{2}) \Rightarrow Y = Y_{1} + Y_{2} \sim \textrm{Poisson}(\mu_{1}+\mu_{2}).$
	\end{itemize}
\end{frame}




\begin{frame}{Poisson distribution as a limit}
	
	The rationale for using the Poisson distribution in many situations is provided by the following proposition.
	
	\vspace*{0.5in}
	
	\begin{proposition}[Limit of a binomial is Poisson]
		Suppose that $Y \sim Binomial(n,\pi)$. If we let $\pi = \mu/n$, then as $n \rightarrow \infty$, $Binomial(n,\pi) \rightarrow Poisson(\mu)$. Another way of saying this: for large $n$ and small $\pi$, we can approximate the $Binomial(n,\pi)$ probability by the $Poisson(\mu = n\pi)$. 
	\end{proposition}
	
\end{frame}


\begin{frame}{Poisson approximation to the Binomial}
	
	
\begin{knitrout}\tiny
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{figure}

{\centering \includegraphics[width=\maxwidth]{figure/unnamed-chunk-12-1} 

}

\caption[Probability mass funtion for Bin(n=100,0.1) and Poisson(10)]{Probability mass funtion for Bin(n=100,0.1) and Poisson(10)}\label{fig:unnamed-chunk-12}
\end{figure}


\end{knitrout}
	
\end{frame}


\begin{frame}
	\frametitle{Examples}
	
	\begin{itemize}
		\setlength\itemsep{0.5em}
		\item numbers of asbestos fibres
		\item deaths from horse kicks*
		\item needle-stick or other percutaneous injuries
		\item bus-driver accidents*
		\item twin-pairs*
		\item radioactive disintegrations*
		\item flying-bomb hits*
		\item white blood cells
		\item typographical errors
		\item cell occupants -- in a given volume, area, line-length, population-time, time, etc. 
		\footnote{\footnotesize * included in \url{http://www.epi.mcgill.ca/hanley/bios601/Intensity-Rate/}}
	\end{itemize}
\end{frame}


\begin{comment}
\begin{frame}
\frametitle{}
\begin{figure}[h]
\begin{center}
\includegraphics[width=3.9in,height=2.6in]{DotsinPopulationTime64.pdf}
\caption{Events in Population-Time randomly generated from intensities that are constant within `panels' (2 squares high by 2 squares wide), but vary between such panels. In Epidemiology, each square might represent a number of units of population-time, and each dot an event.}
\end{center}
\end{figure}
\end{frame}

\begin{frame}
\frametitle{}
\begin{figure}[h]
\begin{center}
\includegraphics[width=4in,height=2in]{timeStrips63.pdf}
\caption{Events in Time: 10 examples, randomly generated from constant over time intensities. Simulated with 1000 Bernoulli$(\tiny{\textrm{small }\pi})$'s per time unit.}
\end{center}
\end{figure}
\end{frame}



\begin{frame}
\frametitle{Does the Poisson Distribution apply to.. ?}

\begin{enumerate}
\setlength\itemsep{0.9em}
\item Yearly variations in numbers of persons killed in	plane crashes 
\item Daily variations in numbers of births
\item Weekly variations in numbers of births
\item Daily variations in numbers of deaths
\item Daily variations in numbers of traffic accidents
\item Variations across cookies/pizzas in numbers of chocolate chips/olives
\end{enumerate}
\end{frame}
\end{comment}



\section{Inference regarding $\mu$, based on observed count $y$}

\begin{frame}[fragile]{Confidence interval for $\mu$}
	\begin{itemize}
		\setlength\itemsep{2em}
		\item If the CLT hasn't kicked in, then the usual CI might not be appropriate: $$\textrm{point-estimate} \pm z^\star  \times \textrm{standard error}$$
		
		\pause 
		
		\item \texttt{qpois} function doesn't work either:
\begin{knitrout}\tiny
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlcom{# middle area is not 95%}
\hlstd{mosaic}\hlopt{::}\hlkwd{xqpois}\hlstd{(}\hlkwd{c}\hlstd{(}\hlnum{0.025}\hlstd{,} \hlnum{0.975}\hlstd{),} \hlkwc{lambda} \hlstd{=} \hlnum{6}\hlstd{)}
\end{alltt}
\end{kframe}

{\centering \includegraphics[width=\maxwidth]{figure/unnamed-chunk-13-1} 

}


\begin{kframe}\begin{verbatim}
## [1]  2 11
\end{verbatim}
\end{kframe}
\end{knitrout}
	\end{itemize}
\end{frame}





\begin{frame}[fragile]{Confidence interval for $\mu$}
	\begin{itemize}
		\setlength\itemsep{2em}
		
		\item Similar to the binomial (Clopper-Pearson CI), we consider a \textit{first-principles} $100(1-\alpha)\%$ CI $[\mu_{LOWER},\: \mu_{UPPER}]$ such that  
		$$P(Y \ge y \: | \: \mu_{LOWER}) = \alpha/2 \:\: \textrm{ and} \:\:  P(Y \le y \: | \: \mu_{UPPER}) = \alpha/2.$$
		\item For example, the  95\% CI for $\mu$, based on $y=6,$ is  $[\underline{2.20}, \underline{13.06}].$ 
	\end{itemize}
\end{frame}




\begin{frame}
	\centering
	\includegraphics[width=3in,height=4in]{CI_Poisson(6).pdf}
\end{frame}


\begin{frame}[fragile]{Poisson 95\% CI for $\mu$ when $y = 6$}
\begin{knitrout}\tiny
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlcom{# upper limit --> lower tail needs 2.5%}
\hlstd{manipulate}\hlopt{::}\hlkwd{manipulate}\hlstd{(}
\hlstd{mosaic}\hlopt{::}\hlkwd{xppois}\hlstd{(}\hlnum{6}\hlstd{,} \hlkwc{lambda} \hlstd{= LAMBDA),}
\hlkwc{LAMBDA} \hlstd{= manipulate}\hlopt{::}\hlkwd{slider}\hlstd{(}\hlnum{0.01}\hlstd{,} \hlnum{20}\hlstd{,} \hlkwc{step} \hlstd{=} \hlnum{0.01}\hlstd{))}


\hlcom{# lower limit --> upper tail needs 2.5%}
\hlcom{# when lower.tail=FALSE, ppois doesnt include k, i.e., P(Y > k)}
\hlstd{manipulate}\hlopt{::}\hlkwd{manipulate}\hlstd{(}
\hlstd{mosaic}\hlopt{::}\hlkwd{xppois}\hlstd{(}\hlnum{5}\hlstd{,} \hlkwc{lambda} \hlstd{= LAMBDA,} \hlkwc{lower.tail} \hlstd{=} \hlnum{FALSE}\hlstd{),}
\hlkwc{LAMBDA} \hlstd{= manipulate}\hlopt{::}\hlkwd{slider}\hlstd{(}\hlnum{0.01}\hlstd{,} \hlnum{20}\hlstd{,} \hlkwc{step} \hlstd{=} \hlnum{0.01}\hlstd{))}
\end{alltt}
\end{kframe}
\end{knitrout}
	
\end{frame}




\begin{frame}
	\frametitle{Confidence interval for $\mu$}
	
	\begin{itemize}
		\setlength\itemsep{1em}
		\item For a given confidence level, there is  one CI for each value of $y$.
		\item Each one can be worked out by trial and error, or -- as has been done for the last 80 years -- directly from the (exact) link between \underline{the tail areas} of the Poisson and \textbf{Gamma} distributions. 
		\item These  CI's  -- for $y$ up to at least 30  -- were found in special books of statistical tables or in textbooks.
		\item As you can check, $z$-based intervals are more than adequate beyond this $y$. \textbf{Today}, if you have access to \texttt{R} (or \texttt{Stata} or \texttt{SAS}) you can obtain the first principles CIs directly \textbf{for \textit{any} value of $y.$} 
	\end{itemize}
\end{frame}



\begin{frame}{80\%, 90\% and 95\% CI for mean count $\mu$ if we observe \underline{0 to 30 events} in a certain amount of experience}
	
	\tiny
	\centering
	\begin{tabular}{|r  | r r  |   r r  |   r r | }
		$y$ & \multicolumn{2}{c}{95\%} & \multicolumn{2}{c}{90\%} & \multicolumn{2}{c}{80\%} \\
		\hline
		0 & 0.00 & 3.69 & 0.00 & 3.00 & 0.00 & 2.30 \\
		1 & 0.03 & 5.57 & 0.05 & 4.74 & 0.11 & 3.89 \\
		2 & 0.24 & 7.22 & 0.36 & 6.30 & 0.53 & 5.32 \\
		3 & 0.62 & 8.77 & 0.82 & 7.75 & 1.10 & 6.68 \\
		4 & 1.09 & 10.24 & 1.37 & 9.15 & 1.74 & 7.99 \\
		& & & & & &  \\
		5 & 1.62 & 11.67 & 1.97 & 10.51 & 2.43 & 9.27 \\
		\underline{6} & \underline{2.20} & \underline{13.06} & 2.61 & 11.84 & 3.15 & 10.53 \\
		7 & 2.81 & 14.42 & 3.29 & 13.15 & 3.89 & 11.77 \\
		8 & 3.45 & 15.76 & 3.98 & 14.43 & 4.66 & 12.99 \\
		9 & 4.12 & 17.08 & 4.70 & 15.71 & 5.43 & 14.21 \\
		& & & & & &  \\
		10 & 4.80 & 18.39 & 5.43 & 16.96 & 6.22 & 15.41 \\
		11 & 5.49 & 19.68 & 6.17 & 18.21 & 7.02 & 16.60 \\
		12 & 6.20 & 20.96 & 6.92 & 19.44 & 7.83 & 17.78 \\
		13 & 6.92 & 22.23 & 7.69 & 20.67 & 8.65 & 18.96 \\
		14 & 7.65 & 23.49 & 8.46 & 21.89 & 9.47 & 20.13 \\
		& & & & & &  \\
		15 & 8.40 & 24.74 & 9.25 & 23.10 & 10.30 & 21.29 \\
		16 & 9.15 & 25.98 & 10.04 & 24.30 & 11.14 & 22.45 \\
		17 & 9.90 & 27.22 & 10.83 & 25.50 & 11.98 & 23.61 \\
		18 & 10.67 & 28.45 & 11.63 & 26.69 & 12.82 & 24.76 \\
		19 & 11.44 & 29.67 & 12.44 & 27.88 & 13.67 & 25.90 \\
		& & & & & &  \\
		20 & 12.22 & 30.89 & 13.25 & 29.06 & 14.53 & 27.05 \\
		21 & 13.00 & 32.10 & 14.07 & 30.24 & 15.38 & 28.18 \\
		22 & 13.79 & 33.31 & 14.89 & 31.41 & 16.24 & 29.32 \\
		23 & 14.58 & 34.51 & 15.72 & 32.59 & 17.11 & 30.45 \\
		24 & 15.38 & 35.71 & 16.55 & 33.75 & 17.97 & 31.58 \\
		\hline
	\end{tabular}
	
\end{frame}



\begin{frame}[fragile]{95\% CI for mean count $\mu$ with \texttt{q} function}
	\begin{itemize}
		\setlength\itemsep{1em}
		\item To obtain these in \texttt{R}	we use the  natural link between the Poisson and  the \textit{gamma} 
		distributions.\footnote{
			{ \tiny \href{http://www.epi.mcgill.ca/hanley/bios601/Mean-Quantile/forAccromathBackTranslate.pdf}{details found here} }} 
		\item In \texttt{R}, e.g., the 95\% limits for $\mu$ based on $y=6$ are obtained as 
		
\begin{knitrout}\tiny
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{qgamma}\hlstd{(}\hlkwc{p} \hlstd{=} \hlkwd{c}\hlstd{(}\hlnum{0.025}\hlstd{,}\hlnum{0.975}\hlstd{),} \hlkwc{shape} \hlstd{=} \hlkwd{c}\hlstd{(}\hlnum{6}\hlstd{,} \hlnum{7}\hlstd{))}
\end{alltt}
\begin{verbatim}
## [1]  2.2 13.1
\end{verbatim}
\end{kframe}
\end{knitrout}
		
		\item More generically, for \textit{any} $y$, as
		
\begin{knitrout}\tiny
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{qgamma}\hlstd{(}\hlkwc{p} \hlstd{=} \hlkwd{c}\hlstd{(}\hlnum{0.025}\hlstd{,}\hlnum{0.975}\hlstd{),} \hlkwc{shape} \hlstd{=} \hlkwd{c}\hlstd{(y, y}\hlopt{+}\hlnum{1}\hlstd{))}
\end{alltt}
\end{kframe}
\end{knitrout}
		
	\end{itemize}
\end{frame}



\begin{frame}[fragile]{95\% CI for mean count $\mu$ with canned function}
	\begin{itemize}
		\setlength\itemsep{1em}
		\item These limits can \underline{also} be found using  the canned function in \texttt{R} 
		
\begin{knitrout}\tiny
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{stats}\hlopt{::}\hlkwd{poisson.test}\hlstd{(}\hlnum{6}\hlstd{)}
\end{alltt}
\begin{verbatim}
## Exact Poisson test with 6 time base: 1 
## number of events = 6, time base = 1, p-value = 0.0005942
## alternative hypothesis: true event rate is not equal to 1 
## 95 percent confidence interval:
##   2.2 13.1 
## sample estimates:
## event rate 
##          6
\end{verbatim}
\end{kframe}
\end{knitrout}
		
	\end{itemize}
\end{frame}



\begin{frame}{$z$-based confidence intervals}
	\scriptsize
	\underline{once $\mu$ is in the upper teens}, the Poisson $\to$ the Normal
	
	\centering
	\includegraphics[scale=0.5]{Shapes.pdf}
	
\end{frame}


\begin{frame}{$z$-based confidence intervals}
	\begin{itemize}
		\setlength\itemsep{1.1em}
		\item Thus, a plus/minus CI based on SE = $\hat{\sigma} =  \sqrt{\hat{\mu}} = \sqrt{y},$   is simply
		$$[ \mu_{L}, \ \mu_{U}] = y  \ \pm \ z^\star \times \sqrt{y}. \ \ \ \ \ \ \ \ \ \ \ \  $$
		\item Equivalently we can use the \texttt{q} function: $$qnorm(p = c(0.025, 0.975), mean = y, sd = \sqrt{y})$$
		
		
		\vspace*{-0.7cm}
		
		\item From a single realization $y$ of a $N(\mu,\sigma_{Y})$ random variable, we can't estimate \textbf{both} $\mu$ and $\sigma_{Y}$: for a SE, we would have to use \textit{outside} information on $\sigma_{Y}$.  
		
		
		
		\item In the  Poisson$(\mu)$ distribution, $\sigma_{Y} = \sqrt{\mu},$ so we  calculate a ``\underline{model-based}'' SE.
		
		%\pause 
		
		%\item \textbf{How large a $y$?}: When $\mu  > 5,$ the distribution isn't `crowded' into the corner:   the lower tail of the Gaussian approximation doesn't  spill over the 0 boundary.
	\end{itemize}
	
\end{frame}


\begin{frame}
	\Wider[8em]{
		\centering
		\includegraphics[width=4.9in,height=3.6in]{PoissonNomogram.pdf}
	}
\end{frame}



\begin{frame}{Note}
	\textbf{How is it that one can form a CI for $\mu$ from a single observation $y$?}
	\vspace{0.2in}
	\pause
	\begin{itemize}
		\item If we had a single realization $y$ of a $\mathcal{N}(\mu, \sigma_{Y})$ random variable, we could not,
		from this single $y$, estimate both $\mu$ and $\sigma_{Y}$
		\item However, the $Poisson(\mu)$ distribution is different in that $\sigma_{Y} = \sqrt{\mu}$ so we can calculate a \textbf{model-based} standard error from this relationship between the mean and the variance
	\end{itemize}
	
\end{frame}


\section{Inference regarding an event rate parameter $\lambda$, based on observed number of events $y$ in a known amount of population-time (PT)}

\begin{frame}{Rates are better for comparisons}
	
	
	\begin{table}
		\centering
		\begin{tabular}{cc}
			year & deaths ($y$) \\
			\hline
			1971 & 33 \\
			2002 & 211 \\
			\hline
		\end{tabular}
		\caption{Deaths from lung cancer in the age-group 55-60 in Quebec in 1971 and 2002}
	\end{table} 
	
	\pause 
	
	\blue{A researcher asks:} Is the situation getting worse over time for lung cancer in this age group?
	\pause
	
	\vspace*{0.5in}
	
	\red{Your reply:} \textbf{What's the denominator??}
	
	
\end{frame} 



\begin{frame}
	\framedgraphic{patrick.png}
\end{frame}





\begin{frame}{Rates are better for comparisons}
	\small
	
	
	
	\begin{itemize}
		\setlength\itemsep{1em}
		
		\item So far, we have focused on inference regarding $\mu$, the expected \textbf{number} of events in the amount of experience actually studied.  
		
		\item However, for \underline{comparison} purposes, the frequency is more often expressed as a \textbf{rate}, \textbf{intensity} or \textbf{incidence density (ID)}. \pause 
	\end{itemize}
	
	\begin{table}
		\centering
		\begin{tabular}{cccc}
			year & deaths ($y$) & person-time (PT)  & rate ($\hat{\lambda}$)  \\
			\hline
			1971 & 33 & 131,200 years & 25 per 100,000 women-years\\
			2002 & 211 & 232,978 years & 91 per 100,000 women-years \\
			\hline
		\end{tabular}
		\caption{Deaths from lung cancer in the age-group 55-60 in Quebec in 1971 and 2002}
	\end{table} 
	
\end{frame} 




\begin{frame}{Rates are better for comparisons}
	\begin{itemize}
		\setlength\itemsep{1.5em}
		
		\item The \textit{statistic}, the empirical rate or empirical incidence density, is 
		$$rate =\hat{ID} = \hat{\lambda} = y/\textrm{PT}.$$  
		
		\item where $y$ is the observed number of events and PT is the amount of Population-Time in which these events were observed. 
		
		\item We think of $\hat{ID}$ or $ \hat{\lambda}$ as a  point estimate of the (theoretical) Incidence Density \textit{parameter}, ID or $\lambda$.
	\end{itemize}
\end{frame} 


\begin{frame}{CI for the rate  parameter $\lambda$}
	
	\begin{itemize}
		\item To calculate a CI for the ID parameter, we \textbf{treat the PT \underline{denominator} as a constant}, and the \textbf{\underline{numerator}, $y$,  as a Poisson random variable}, with expectation $E[y] = \mu = \lambda \times PT$, so that
		\begin{align*}
		\lambda &= \mu \div \textrm{PT}\\
		\hat{\lambda} &= \hat{\mu} \div \textrm{PT} \\
		& = y\div\textrm{ PT}
		\end{align*}
		
		
		
		\vspace*{0.3in}
		\begin{equation}
		\boxed{\textrm{CI for }\lambda = \{\textrm{CI for }\mu\} \div \textrm{PT}.}
		\end{equation}
		
		
	\end{itemize}
\end{frame}


\begin{frame}[fragile]{CI for the rate  parameter $\lambda$}
	
	
	\begin{itemize}
		\setlength\itemsep{1.5em}
		\small
		\item $y=211$ deaths from lung cancer in 2002 leads to a 95\% CI for $\mu$:
		
\begin{knitrout}\tiny
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{qgamma}\hlstd{(}\hlkwc{p} \hlstd{=} \hlkwd{c}\hlstd{(}\hlnum{0.025}\hlstd{,} \hlnum{0.975}\hlstd{),} \hlkwc{shape} \hlstd{=} \hlkwd{c}\hlstd{(}\hlnum{211}\hlstd{,} \hlnum{212}\hlstd{))}
\end{alltt}
\begin{verbatim}
## [1] 183 241
\end{verbatim}
\end{kframe}
\end{knitrout}
		
		\pause 
		
		\item From this we can calculate the 95\% CI \textbf{per 100,000 WY} for $\lambda$ using a PT=232978 years:
		
\begin{knitrout}\tiny
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{qgamma}\hlstd{(}\hlkwc{p} \hlstd{=} \hlkwd{c}\hlstd{(}\hlnum{0.025}\hlstd{,} \hlnum{0.975}\hlstd{),} \hlkwc{shape} \hlstd{=} \hlkwd{c}\hlstd{(}\hlnum{211}\hlstd{,} \hlnum{212}\hlstd{))} \hlopt{/} \hlnum{232978} \hlopt{*} \hlnum{1e5}
\end{alltt}
\begin{verbatim}
## [1]  79 104
\end{verbatim}
\end{kframe}
\end{knitrout}
		
		\pause
		
		\item $y=33$ deaths from lung cancer in 131200 women-years in 1971 leads to a 95\% CI per 100,000 WY for $\lambda$ of
		
\begin{knitrout}\tiny
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{qgamma}\hlstd{(}\hlkwd{c}\hlstd{(}\hlnum{0.025}\hlstd{,}\hlnum{0.975}\hlstd{),} \hlkwd{c}\hlstd{(}\hlnum{33}\hlstd{,}\hlnum{34}\hlstd{))} \hlopt{/} \hlnum{131200} \hlopt{*} \hlnum{1e5}
\end{alltt}
\begin{verbatim}
## [1] 17 35
\end{verbatim}
\end{kframe}
\end{knitrout}
		
		
	\end{itemize}
	
\end{frame}


\begin{frame}[fragile]{CI for the rate  parameter $\lambda$ using canned function}
	
\begin{knitrout}\tiny
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{stats}\hlopt{::}\hlkwd{poisson.test}\hlstd{(}\hlkwc{x} \hlstd{=} \hlnum{33}\hlstd{,} \hlkwc{T} \hlstd{=} \hlnum{131200}\hlstd{)}
\end{alltt}
\begin{verbatim}
## Exact Poisson test with 33 time base: 131200 
## number of events = 33, time base = 131200, p-value < 2.2e-16
## alternative hypothesis: true event rate is not equal to 1 
## 95 percent confidence interval:
##  0.00017 0.00035 
## sample estimates:
## event rate 
##    0.00025
\end{verbatim}
\end{kframe}
\end{knitrout}
	
\end{frame}



\section{Test of $H_{0}: \mu = \mu_{0}$ $\quad \Leftrightarrow \quad$ $\lambda = \lambda_{0}$}


\begin{frame}{Statistical evidence and the $p$-value}
	
	\textbf{Recall:}
	
	\vspace*{1cm}
	
	\begin{itemize}
		\setlength\itemsep{1.2em}
		\item P-Value = Prob[$y$ or more extreme $ |\:H_{0}$]
		
		\item With `more extreme' determined by whether $H_{alt}$ is  1-sided or 2-sided. 
		
		\item For a \textbf{formal test}, at level $\alpha$, compare this P-value with $\alpha$.
	\end{itemize}
	
\end{frame}



\begin{frame}{Example: Cancers surrounding nuclear stations}
	\small
	
	\begin{itemize}
		\setlength\itemsep{.3em}
		\item Cancers in area surrounding the Douglas Point nuclear station \pause
		\item Denote by $\{CY_{1},CY_{2}, \dots \}$ the numbers of Douglas Point \underline{c}hild-\underline{y}ears of experience in the various age categories that were pooled over.  
		\item Denote by $\{\lambda^{Ont}_{1}, \lambda^{Ont}_{2},  \dots \}$ the age-specific leukemia incidence rates during the period studied. \pause
		\item If the underlying incidence rates in Douglas Point were the same as those in the rest of Ontario, the \textbf{\textit{E}}xpected total number of cases of leukemia for Douglas Point would be
		
		$$E = \mu_{0} = \sum_{ages} CY_{i} \times \lambda^{Ont}_{i}  = 0.57.$$
		\pause
		The actual total number of cases of leukemia \textbf{\textit{O}}bserved in Douglas Point was 
		$$O = y = \sum_{ages} O_{i}  = 2.$$
		\pause
		Age \textit{Standardized Incidence Ratio (SIR)} = $O/E = 2/0.57 = 3.5.$
	\end{itemize}
	
\end{frame}





\begin{frame}{Q: Is the $O=2$ significantly higher than $E=0.57$}
	
	\blue{Question:}
	
	\begin{itemize}
		\setlength\itemsep{1.2em}
		\item Is the $y = 2$ cases of leukemia observed in the Douglas Point experience statistically significantly \underline{higher} than the $E=0.57$  cases ``expected'' for this many child-years of  observation  if in fact the rates in Douglas Point and the rest of Ontario were the same? 
		\item Or, is the $y=2$ observed in this community compatible with $H_{0}: y \sim \textrm{Poisson}(\mu = 0.57)$?
	\end{itemize}
	
\end{frame}










\begin{frame}[fragile]{A: Is the $O=2$ significantly higher than $E=0.57$}
	\small
	\begin{itemize}
		\setlength\itemsep{1.2em}
		\item \red{Answer:} Under  $H_{0}$, the age-specific numbers of leukemias $\{y_{1}=O_{1},\: y_{2}=O_{2},\: \dots \}$ in Douglas Point can be regarded as independent Poisson random variables, so their sum $y$ can be regarded as a single Poisson random variable with $\mu=0.57$. 
		
\begin{knitrout}\tiny
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{mosaic}\hlopt{::}\hlkwd{xppois}\hlstd{(}\hlnum{1}\hlstd{,} \hlkwc{lambda} \hlstd{=} \hlnum{0.57}\hlstd{,} \hlkwc{lower.tail} \hlstd{=} \hlnum{FALSE}\hlstd{)}
\end{alltt}
\end{kframe}

{\centering \includegraphics[width=\maxwidth]{figure/unnamed-chunk-22-1} 

}


\begin{kframe}\begin{verbatim}
## [1] 0.11
\end{verbatim}
\end{kframe}
\end{knitrout}
		
		
	\end{itemize}
	
\end{frame}


\begin{frame}[fragile]{95\% CI for the SIR by hand}
	
	
	\small
	\begin{itemize}
		\setlength\itemsep{1.2em}
		
		\item To get the \underline{CI for the SIR}, divide the CI for Douglas Point $\mu_{DP}$ by the null $\mu_0 = 0.57$ (Ontario scaled down to the same size and age structure as Douglas Point.) We treat it as a constant because the Ontario rates used in the scaling are measured with much less sampling variability that the Douglas Point ones.
		
		\pause 
		
		\item The $y$ = 2 cases translates to
		\begin{itemize}
			\item 95\% CI for $\mu_{DP}$ $\to$ [0.24, 7.22]
			\item 95\% CI for the SIR $\to$ [0.24/0.57, 7.22/0.57]=[0.4, 12.7].
		\end{itemize}
	\end{itemize}
	
\end{frame}



\begin{frame}[fragile]{95\% CI for the SIR using canned function}
	
	
	\small
	\begin{itemize}
		\setlength\itemsep{1.2em}
		
		\item We can \textit{trick}  \texttt{stats::poisson.test} 
		to get the same CI by putting time as 0.57: 
		
		
	\end{itemize}
	
\begin{knitrout}\tiny
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{stats}\hlopt{::}\hlkwd{poisson.test}\hlstd{(}\hlkwc{x}\hlstd{=}\hlnum{2}\hlstd{,}\hlkwc{T}\hlstd{=}\hlnum{0.57}\hlstd{)}
\end{alltt}
\begin{verbatim}
## Exact Poisson test with 2 time base: 0.57 
## number of events = 2, time base = 0.57, p-value = 0.1121
## alternative hypothesis: true event rate is not equal to 1 
## 95 percent confidence interval:
##   0.42 12.67 
## sample estimates:
## event rate 
##        3.5
\end{verbatim}
\end{kframe}
\end{knitrout}
	
\end{frame}



%\begin{frame}[allowframebreaks]
%\nocite{breiman1984classification}
%	\nocite{friedman2001elements}
%	\nocite{james2013introduction}
%	\nocite{lopez2015arbres}
%	\frametitle{References}
%\printbibliography
%\end{frame}


\begin{frame}[fragile]{Session Info}
	\tiny
	
\begin{knitrout}\tiny
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{verbatim}
R version 4.0.2 (2020-06-22)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: Pop!_OS 20.04 LTS

Matrix products: default
BLAS:   /usr/lib/x86_64-linux-gnu/openblas-pthread/libblas.so.3
LAPACK: /usr/lib/x86_64-linux-gnu/openblas-pthread/liblapack.so.3

attached base packages:
[1] tools     stats     graphics  grDevices utils     datasets  methods  
[8] base     

other attached packages:
 [1] NCStats_0.4.7   FSA_0.8.30      forcats_0.5.0   stringr_1.4.0  
 [5] dplyr_1.0.2     purrr_0.3.4     readr_1.3.1     tidyr_1.1.2    
 [9] tibble_3.0.3    ggplot2_3.3.2   tidyverse_1.3.0 knitr_1.29     

loaded via a namespace (and not attached):
 [1] fs_1.5.0           lubridate_1.7.9    httr_1.4.2         latex2exp_0.4.0   
 [5] backports_1.1.9    R6_2.4.1           DBI_1.1.0          colorspace_1.4-1  
 [9] withr_2.2.0        tidyselect_1.1.0   gridExtra_2.3      leaflet_2.0.3     
[13] curl_4.3           compiler_4.0.2     cli_2.0.2          rvest_0.3.6       
[17] xml2_1.3.2         ggdendro_0.1.22    labeling_0.3       mosaicCore_0.8.0  
[21] scales_1.1.1       digest_0.6.25      ggformula_0.9.4    foreign_0.8-79    
[25] rio_0.5.16         pkgconfig_2.0.3    htmltools_0.5.0    dbplyr_1.4.4      
[29] highr_0.8          htmlwidgets_1.5.1  rlang_0.4.7        readxl_1.3.1      
[33] rstudioapi_0.11    farver_2.0.3       generics_0.0.2     jsonlite_1.7.1    
[37] crosstalk_1.1.0.1  zip_2.1.1          car_3.0-9          magrittr_1.5      
[41] mosaicData_0.20.1  Matrix_1.2-18      Rcpp_1.0.5         munsell_0.5.0     
[45] fansi_0.4.1        abind_1.4-5        lifecycle_0.2.0    stringi_1.5.3     
[49] carData_3.0-4      MASS_7.3-53        plyr_1.8.6         ggstance_0.3.4    
[53] grid_4.0.2         blob_1.2.1         ggrepel_0.8.2      crayon_1.3.4      
[57] lattice_0.20-41    haven_2.3.1        splines_4.0.2      hms_0.5.3         
[61] pillar_1.4.6       reprex_0.3.0       glue_1.4.2         evaluate_0.14     
[65] data.table_1.13.0  modelr_0.1.8       vctrs_0.3.4        tweenr_1.0.1      
[69] cellranger_1.1.0   gtable_0.3.0       polyclip_1.10-0    assertthat_0.2.1  
[73] TeachingDemos_2.12 xfun_0.17          ggforce_0.3.2      openxlsx_4.1.5    
[77] broom_0.7.0        viridisLite_0.3.0  mosaic_1.7.0       ellipsis_0.3.1    
\end{verbatim}
\end{kframe}
\end{knitrout}
	
\end{frame}

\end{document}

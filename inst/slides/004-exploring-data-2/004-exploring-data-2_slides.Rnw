\documentclass[10pt]{beamer}


%\input{slides_header.tex}
\input{/home/sahir/git_repositories/EPIB607/slides/slides_header2.tex}
\graphicspath{{/home/sahir/git_repositories/EPIB607/slides/figure/}}

%\let\oldShaded\Shaded
%\let\endoldShaded\endShaded
%\renewenvironment{Shaded}{\footnotesize\oldShaded}{\endoldShaded}



\begin{document}
	
	<<setup, include=FALSE>>=
	library(knitr)
	knitr::opts_chunk$set(cache=FALSE, message = FALSE, tidy = FALSE, warning = FALSE,
	echo = FALSE, 
	#fig.width = 8, 
	#fig.asp = 0.8, 
	fig.align = 'center', 
	#out.width = "0.50\\linewidth", 
	size = 'tiny')
	
	# the kframe environment does not work with allowframebreaks, so remove it
	#knit_hooks$set(document = function(x) {
	#gsub('\\\\(begin|end)\\{kframe\\}', '', x)
	#})
	
	library(tidyverse)
	library(NCStats)
	options(digits = 2)

	
	#knitr::opts_chunk$set(background = '#FFFF00')
	library(tools) #needed for include_graphics2 function
	pacman::p_load(here)
	source(here::here("inst","slides","bin","include_graphics2.R"))
	knitr::knit_hooks$set(purl = hook_purl)
	@
	
	%\title{Introduction to Regression Trees}
	%\author{Sahir Bhatnagar \inst{1}}
	%\author[shortname]{Sahir Rai Bhatnagar, PhD Candidate (Biostatistics) }
	%\institute[shortinst]{Department of Epidemiology, Biostatistics and Occupational Health}
	
	\title{004 - Exploring Data - Part II}
	\author{EPIB 607}
%\title{Descriptive Statistics Part II}
%\author{Lecture 6}
	\institute{
		Sahir Rai Bhatnagar\\
%		Department of Epidemiology, Biostatistics, and Occupational Health\\
Department of Radiology
		McGill University\\
		
		\vspace{0.1 in}
		
		\texttt{sahir.bhatnagar@mcgill.ca}\\
		%\texttt{\url{https://sahirbhatnagar.com/EPIB607/}}
	}
	
	\date{slides compiled on \today}
	
	\maketitle

	
	

						
\begin{frame}{Summarizing relationships between two variables}
							\protect\hypertarget{summarizing-relationships-between-two-variables}{}
							
							Approaches for summarizing relationships between two variables vary
							depending on variable types:
							
							\begin{itemize}
								\item
								Two numerical variables
								\item
								Two categorical variables
								\item
								One numerical variable and one categorical variable
							\end{itemize}
							
\end{frame}


\section{Two numerical variables and the correlation coefficient}


\begin{frame}[fragile]{Scatterplots}
	\protect\hypertarget{two-numerical-variables-1}{}
	
	\small
	
	\scriptsize
	
	
	<<numerical, echo=TRUE, size = 'scriptsize', out.width="0.45\\linewidth", fig.subcap=c('base \\texttt{graphics} package', '\\texttt{ggplot2} package')>>=
	library(ggplot2); library(oibiostat); 
	data(famuss) 
	
	plot(famuss$height, famuss$weight, xlab = "Height (in)", ylab = "Weight (lb)")
	
	ggplot(data = famuss, mapping = aes(x = height, y = weight)) + 
	  geom_point(size = 0.8, pch = 21)
	@	
	
	\normalsize
	
\end{frame}



						
						\begin{frame}{Pearson's correlation coefficient}
							\protect\hypertarget{two-numerical-variables}{}
							
								\begin{itemize}
							
							\item The \textbf{\textcolor{red}{sample}} correlation ($r$) between two variables $X$ and $Y$ is given by:							
							\begin{align}
							r &= \frac{1}{n-1} \sum_{i=1}^n z_X \cdot z_Y \\ 
							&=\frac{1}{n-1} \sum_{i=1}^{n}\left(\frac{x_{i}-\bar{x}}{s_{X}}\right)\left(\frac{y_{i}-\bar{y}}{s_{Y}}\right)
							\end{align}
							
							\item $\left(x_{1}, y_{1}\right),\left(x_{2}, y_{2}\right), \ldots,\left(x_{n}, y_{n}\right)$ the $n$ paired sample values of $X$ and $Y$
							
							\item $z_{X}$ and $z_{Y}$ are the sample Z-scores of the $X$ and $Y$ variables, respectively 
							
							\item $s_{X}$ and $s_{Y}$ are the sample standard deviations of the $X$ and $Y$ variables, respectively 
							
							\item $\bar{x}$ and $\bar{y}$ are the sample means of the X and Y variables, respectively
							
							
							\pause 
							
							\item The correlation coefficient quantifies the strength of a \textbf{\textcolor{red}{linear}} trend.
							
						
													\end{itemize}
							
							
						\end{frame}
						



\begin{frame}[fragile]{Plot of weight vs. height in \texttt{famuss} dataset}
	
	<<echo=FALSE, fig.asp = 0.681>>=
	library(oibiostat)
	library(openintro)
	data("COL")
	data("famuss")
	
	
	#cor(famuss$height, famuss$weight)
	#plot(famuss$height, famuss$weight)
	
	#(1/(nrow(famuss)-1)) * sum(scale(famuss$height)*scale(famuss$weight))
	
	zx <- famuss$height
	zy <- famuss$weight
	
	
	plot(zx,
	zy, 
	pch = 19,
	cex = 1.3,
	col = COL[1, 3],
	type = "n",
	bty = "n",
	xlab = "height Z-scores",
	ylab = "weight Z-scores")
	points(zx,
	zy,
	pch = 19,
	cex = 1.3,
	col = COL[5,3])
	points(zx,
	zy,
	cex = 1.3,
	col = COL[5])
	@
	
\end{frame}


\begin{frame}[fragile]{Plot of Z-scores weight vs. Z-scores height in \texttt{famuss} dataset}

<<echo=FALSE, fig.asp = 0.681>>=
library(oibiostat)
library(openintro)
data("COL")
data("famuss")


#cor(famuss$height, famuss$weight)
#plot(famuss$height, famuss$weight)

#(1/(nrow(famuss)-1)) * sum(scale(famuss$height)*scale(famuss$weight))

zx <- scale(famuss$height)
zy <- scale(famuss$weight)


 
plot(zx,
zy, 
pch = 19,
cex = 1.3,
col = COL[1, 3],
type = "n",
#xlim = xlims,
#ylim = ylims,
bty = "n",
xlab = "height Z-scores",
ylab = "weight Z-scores")
points(zx,
zy,
pch = 19,
cex = 1.3,
col = COL[5,3])
points(zx,
zy,
cex = 1.3,
col = COL[5])
@

\end{frame}



\begin{frame}[fragile]{Partition the graph into four quadrants $(x,y)$}
	
	<<echo=FALSE, fig.asp = 0.681>>=
	library(oibiostat)
	library(openintro)
	data("COL")
	data("famuss")
	
	
	#cor(famuss$height, famuss$weight)
	#plot(famuss$height, famuss$weight)
	
	#(1/(nrow(famuss)-1)) * sum(scale(famuss$height)*scale(famuss$weight))
#xlims <- c(-ceiling(abs(max(zx))),ceiling(abs(max(zx))))
#ylims <- c(-ceiling(abs(max(zy))),ceiling(abs(max(zy))))
xlims <- range(zx)
ylims <- range(zy)
	plot(zx,
	zy, 
	pch = 19,
	cex = 1.3,
	col = COL[1, 3],
	type = "n",
	xlim = xlims,
	ylim = ylims,
	bty = "n",
	xlab = "height Z-scores",
	ylab = "weight Z-scores")
	polygon(x = c(0,max(xlims), max(xlims), 0)*1.1, y = c(0,0, max(ylims), max(ylims))*1.1, col = "#56B4E9")
	polygon(x = c(0,min(xlims), min(xlims), 0)*1.1, y = c(0,0, min(ylims), min(ylims))*1.2, col = "#56B4E9")
	polygon(x = c(0,min(xlims), min(xlims), 0)*1.1, y = c(0,0, max(ylims), max(ylims))*1.1, col = "#D55E00")
	polygon(x = c(0,max(xlims), max(xlims), 0)*1.1, y = c(0,0, min(ylims), min(ylims))*1.2, col = "#D55E00")
	text(-2.7, 4.4, "(-,+)", cex = 1.5)
	text(2.7, 4.4, "(+,+)", cex = 1.5)
	text(2.7, -2.2, "(+,-)", cex = 1.5)
	text(-2.7, -2.2, "(-,-)", cex = 1.5)
	@
	
\end{frame}


\begin{frame}[fragile]{Correlation depends on which quadrants the points are on}
	
	<<echo=FALSE, fig.asp = 0.681>>=
	library(oibiostat)
	library(openintro)
	data("COL")
	data("famuss")
	
	
	#cor(famuss$height, famuss$weight)
	#plot(famuss$height, famuss$weight)
	
	#(1/(nrow(famuss)-1)) * sum(scale(famuss$height)*scale(famuss$weight))
	
	plot(zx,
zy, 
pch = 19,
cex = 1.3,
col = COL[1, 3],
type = "n",
xlim = xlims,
ylim = ylims,
bty = "n",
xlab = "height Z-scores",
ylab = "weight Z-scores")
polygon(x = c(0,max(xlims), max(xlims), 0)*1.1, y = c(0,0, max(ylims), max(ylims))*1.1, col = "#56B4E9")
polygon(x = c(0,min(xlims), min(xlims), 0)*1.1, y = c(0,0, min(ylims), min(ylims))*1.2, col = "#56B4E9")
polygon(x = c(0,min(xlims), min(xlims), 0)*1.1, y = c(0,0, max(ylims), max(ylims))*1.1, col = "#D55E00")
polygon(x = c(0,max(xlims), max(xlims), 0)*1.1, y = c(0,0, min(ylims), min(ylims))*1.2, col = "#D55E00")
text(-2.7, 4.4, "(-,+)", cex = 1.5)
text(2.7, 4.4, "(+,+)", cex = 1.5)
	text(2.7, -2.2, "(+,-)", cex = 1.5)
text(-2.7, -2.2, "(-,-)", cex = 1.5)
	points(zx,
	zy,
	pch = 19,
	cex = 1.3,
	col = COL[5,3])
	points(zx,
	zy,
	cex = 1.3,
	col = COL[5])
	@
	
\end{frame}






						
\begin{frame}{Pearson's correlation coefficient}
	\protect\hypertarget{two-numerical-variables}{}
	
	\begin{itemize}
		
		
		\item
		The correlation coefficient \(r\) takes on values between -1 and 1.
		\pause 
		\item
		The closer \(r\) is to \(\pm 1\), the stronger the linear association.
		\pause 
		
		\item 	Two variables \(X\) and \(Y\) are
		
		\begin{itemize}
			\item
			\emph{positively associated} if \(Y\) increases as \(X\) increases ($r>0$)
			\item
			\emph{negatively associated} if \(Y\) decreases as \(X\) increases ($r<0$)
		\end{itemize}
	
	\pause 
	
	\item Since the formula for calculating the correlation coefficient standardizes the variables, changes in scale or units of measurement will not affect its value
		
	\end{itemize}
	
	
\end{frame}





\begin{frame}{Exercise: Show mathematically that the correlation ($r$) is bounded by -1 and 1}
	\pause 
	Consider that we can't have higher correlation than when we compare a list to itself (perfect correlation).
	\vspace{4in}
\end{frame}


\begin{frame}{Correlation and Simple linear Regression}
	\begin{itemize}
		\item 
If we are predicting a random variable $Y$ knowing the value of another
variable $X=x$ using a regression line, then the formula for the regression can be given by:
\begin{equation}
\left(\frac{Y-\bar{y}}{s_{Y}}\right)=r\left(\frac{x-\bar{x}}{s_{X}}\right)
\end{equation}

\item This can be rewritten as:
\begin{align}
Y &= \bar{y}+r\left(\frac{x-\bar{x}}{s_{X}}\right) s_{Y}
\end{align}

	\end{itemize}
\end{frame}








						
\begin{frame}[fragile]{Correlation in \texttt{R}}
							\protect\hypertarget{two-numerical-variables-2}{}

							\begin{itemize}							
		\item Correlation between weight and height in the \texttt{famuss} dataset:
							
						
						
							<<cor, echo=TRUE, size = 'scriptsize'>>=
							cor(famuss$height, famuss$weight)
							@	
							
							\pause
							
							\item We can also obtain the correlation between \texttt{weight} and \texttt{height} from a simple linear regression:
							
							<<cor2, echo=TRUE, size = 'scriptsize'>>=
							summary(lm(height ~ weight, data = famuss))
							@
						
						\pause
						
						\item Exercise: calculate the correlation coefficient from the regression coefficient for weight. 
						
							\normalsize
							
					\end{itemize}
							
\end{frame}


\begin{frame}{Let's remind ourselves about random variability}
\begin{itemize}
	\item In many cases, we do not observe data for the entire population of interest but rather for a random sample. 
	\item As with the mean and standard deviation, the sample correlation is the most commonly used estimator of the population correlation. 
	\item This implies that the correlation we compute and use as a summary is a random variable.
\end{itemize}
\end{frame}



\begin{frame}[fragile]{Let's remind ourselves about random variability}
\small 
Lets create a pseudo population from the 595 observations by sampling \textbf{with replacement}, and calculate the correlation. Lets repeat this process 1000 times: 
		<<echo = TRUE, out.width= "0.3\\linewidth">>=
		B <- 1000; N <- 595
		R <- replicate(B, {
		        dplyr::sample_n(famuss, size = N, replace = TRUE) %>% 
		        dplyr::summarize(r = cor(height, weight)) %>% 
		        dplyr::pull(r)
		})
	@

\begin{figure}
	\begin{minipage}[h]{0.30\linewidth}
		<<bootmean, echo=TRUE, size = 'tiny'>>=
		mean(R)
		quantile(R, probs = c(0.025, 0.975))
		@
	\end{minipage}
	\hspace{0.4cm}
	\begin{minipage}[h]{0.59\linewidth}
		<<histboot,echo=TRUE, size = "tiny", fig.asp = 0.681>>=
		hist(R, breaks = 20, col = "lightblue", xlab = "correlation", 
		     main = "Distribution of samples of size 595")
		abline(v = mean(R), col = "red", lwd = 2)
		abline(v = quantile(R, probs = c(0.025, 0.975)), col = "blue", 
		       lty = 2, lwd = 2)
		@
	\end{minipage}
\end{figure}



\end{frame}



\begin{frame}{Another example: NHANES\footnote{\tiny{\url{http://www.cdc.gov/nchs/nhanes.htm}}}}
	\begin{itemize}
		\item The National Health and Nutrition Examination Survey (NHANES) consists of a set of surveys and measurements conducted by the US CDC to assess the health and nutritional status of adults	and children in the United States. 
		\item The following example uses data from a sample of 500 adults (individuals ages 21 and older) from the NHANES dataset\footnote{\tiny{The sample is available as \texttt{nhanes.samp.adult.500} in the \texttt{R} \code{oibiostat} package}}.
	\end{itemize}
\end{frame}

\begin{frame}[fragile,plain]

\vspace{-0.5in}	
	
<<echo=FALSE, fig.cap = c('(a) A scatterplot showing height versus weight from the 500 individuals in the sample from NHANES. One participant 163.9 cm tall (about 5 ft, 4 in) and weighing 144.6 kg (about 319 lb) is highlighted. (b) A scatterplot showing height versus BMI from the 500 individuals in the sample from NHANES. The same individual highlighted in (a) is marked here, with BMI 53.83. Fitted regression lines are shown in red with correlation coefficient $r$. BMI = weight/height$^2$ $\\times 703$.'), fig.subcap = c('',''), out.width='0.55\\linewidth'>>=
library(openintro)
data(COL)
library(oibiostat)
data(nhanes.samp.adult.500)

plot(nhanes.samp.adult.500$Height,
nhanes.samp.adult.500$Weight,
pch = 19,
cex = 1.3,
col = COL[1, 3],
xlab = "",
ylab = "Weight (kg)")
points(nhanes.samp.adult.500$Height,
nhanes.samp.adult.500$Weight,
cex = 1.3,
col = COL[1])
mtext("Height (cm)", 1, 1.9)

t1 <- nhanes.samp.adult.500$Height[480]
t2 <- nhanes.samp.adult.500$Weight[480]
lines(c(t1, t1), c(-10, t2),
lty = 2,
col = COL[4])
lines(c(-10, t1), c(t2, t2),
lty = 2,
col = COL[4])
points(t1, t2,
pch = 19,
cex = 1.3,
col = COL[4, 3],)

data("nhanes.samp.adult.500")
nhanes.dat <- nhanes.samp.adult.500[,c("Height","Weight","BMI")]
nhanes.dat <- na.omit(nhanes.dat)
fit <- lm(Weight~Height, data = nhanes.dat)
lines(nhanes.dat$Height,
fit$fitted.values,col="red")
text(190,50, sprintf("r = %0.2f",summary(fit)$r.squared^0.5),cex=2)



plot(nhanes.samp.adult.500$Height,
nhanes.samp.adult.500$BMI,
pch = 19,
cex = 1.3,
col = COL[1, 3],
xlab = "",
ylab = "BMI")
points(nhanes.samp.adult.500$Height,
nhanes.samp.adult.500$BMI,
cex = 1.3,
col = COL[1])
mtext("Height (cm)", 1, 1.9)

t1 <- nhanes.samp.adult.500$Height[480]
t2 <- nhanes.samp.adult.500$BMI[480]
lines(c(t1, t1), c(-10, t2),
lty = 2,
col = COL[4])
lines(c(-10, t1), c(t2, t2),
lty = 2,
col = COL[4])
points(t1, t2,
pch = 19,
cex = 1.3,
col = COL[4, 3],)
fit <- lm(BMI~Height, data = nhanes.dat)
lines(nhanes.dat$Height,
fit$fitted.values,col="red")
text(190,50, sprintf("r = %0.2f",summary(fit)$r.squared^0.5),cex=2)
@	
	
\end{frame}




\frame{\frametitle{Cautionary notes}
	\begin{itemize}
		
		\item The formulas above are for a \underline{particular sample}, hence the lower case letters $r,x,y$. In statistical terms, $r$ is the \textbf{estimator} for the population-level correlation $\rho$ (the \textbf{estimand}) of the random variables $X$ and $Y$. The actual value of the sample correlation is denoted by $\widehat{r}$ and is called the \textbf{estimate}
		
		\pause
		
	
		\item This implies that we are not 100\% confident in our estimate and therefore should provide a confidence interval  as well.
		
		\pause
		

		
		\item A strong linear relationship is not necessarily a
		\textbf{causal} relationship, that is, just because $r \approx 1$ (or $r \approx -1$)
		does not mean that $x$ \textbf{causes} changes in $y$ (we may have a \textit{spurious}
		correlation).  \pause
		
		
		
		\item Just because $r \approx 0$ does not mean that that $x$ and $y$
		are unrelated, merely that they are \textbf{uncorrelated}. That
		is, it is possible to construct examples where $x$ and $y$ have
		a strong functional relationship, but where $r=0$.
		
		\item $X,Y$ independent $\Rightarrow$ $r_{XY} = 0$
		\item $r_{XY} = 0$ $\not \Rightarrow$ $X,Y$ are independent
		
	\end{itemize}


	
}





\begin{frame}[fragile]{Anscombe's quartet\footnote{\tiny{Anscombe, Francis J. (1973). Graphs in statistical analysis. The American Statistician, 27, 17â€“21. doi: 10.2307/2682899.}}}
	
<<echo=c(1), size = 'tiny', out.width='0.55\\linewidth', fig.cap = 'All four panels have the exact same linear correlation coefficient'>>=
library(datasets);data("anscombe")
ff <- y ~ x
mods <- setNames(as.list(1:4), paste0("lm", 1:4))
for(i in 1:4) {
ff[2:3] <- lapply(paste0(c("y","x"), i), as.name)
## or   ff[[2]] <- as.name(paste0("y", i))
##      ff[[3]] <- as.name(paste0("x", i))
mods[[i]] <- lmi <- lm(ff, data = anscombe)
}
## Now, do what you should have done in the first place: PLOTS
op <- par(mfrow = c(2, 2), mar = 0.1+c(4,4,1,1), oma =  c(0, 0, 2, 0))
for(i in 1:4) {
ff[2:3] <- lapply(paste0(c("y","x"), i), as.name)
plot(ff, data = anscombe, col = "red", pch = 21, bg = "orange", cex = 1.2,
xlim = c(3, 19), ylim = c(3, 13))
abline(mods[[i]], col = "blue")
text(15,4,sprintf("r = %0.2f",summary(mods[[i]])$r.squared^0.5), cex = 2)
}
mtext("Anscombe's 4 Regression data sets", outer = TRUE, cex = 1.5)
par(op)
@	


\end{frame}



\begin{frame}[fragile]{Zero linear correlation does not imply independence}
	<<echo=TRUE, fig.asp = 0.481, size = "scriptsize">>=
	set.seed(12)
	x <- runif(100,-1,1)
	y <- x^2
	plot(x,y, pch = 19)
	cor(x,y)
	@
\end{frame}


\begin{frame}{Another example of same summary statistics but very different relationships}
\url{https://www.autodeskresearch.com/publications/samestats}
\end{frame}




\begin{frame}[fragile,plain]{Transformations to improve linear fit}
	
	<<004-nyt, echo = FALSE, out.width = "0.53\\linewidth", fig.subcap=c('',''), fig.cap=c('(a) per capita income vs. life expectancy (b) log per capita income vs. life expectancy. Fitted regression line in red with correlation coefficient $r$.\\footnote{\\tiny{The World Development Indicators (WDI) is a database of country-level variables (i.e., indicators) recording outcomes for a variety of topics, including economics, health, mortality, fertility, and education}}')>>=
library(openintro)
library(oibiostat)
data("wdi.2011")
data(COL)

plot(wdi.2011$life.expect,
wdi.2011$gdp.per.capita,
pch = 19,
cex = 1.3,
col = COL[1, 3],
xlab = "Life Expectancy (years)",
ylab = "Per Capita Income (USD)",
axes = FALSE)
fit1 <- lm(gdp.per.capita~life.expect, data = wdi.2011)
lines(wdi.2011$life.expect,
fit1$fitted.values,col="red")
points(wdi.2011$life.expect,
wdi.2011$gdp.per.capita,
cex = 1.3,
col = COL[1])
AxisInDollars(2, pretty(wdi.2011$gdp.per.capita))
axis(1)
text(55,1e5, sprintf("r = %0.2f",summary(fit1)$r.squared^0.5), cex = 2)


plot(wdi.2011$life.expect,
log(wdi.2011$gdp.per.capita),
pch = 19,
cex = 1.3,
col = COL[1, 3],
xlab = "Life Expectancy (years)",
ylab = "log(Per Capita Income (USD))",
axes = FALSE)
fit2 <- lm(log(gdp.per.capita)~life.expect, data = wdi.2011)
lines(wdi.2011$life.expect,
fit2$fitted.values,col="red")
AxisInDollars(2, pretty(log(wdi.2011$gdp.per.capita)))
axis(1)
text(55,11, sprintf("r = %0.2f",summary(fit2)$r.squared^0.5), cex = 2)
	@
	
\end{frame}



\frame{\frametitle{Rank correlation} The Pearson correlation,
	recall, is a measure of \textit{linear} association. This may
	be undesirable for a number of reasons:
	\begin{itemize}
		\item $y$ and $x$ may be related, but not linearly (e.g., shape
		may be quadratic) \pause
		\item one or both of $y$ and $x$ may be an ordered categorical
		variable (e.g., highest level of education attained, income category, age group, etc.)
		and the investigator may not wish to impose a particular numerical scale \pause
		\item A nonparametric approach may be preferred if $y$ or $x$
		are thought not to be Normally distributed
	\end{itemize}
	We can overcome these concerns using a correlation that is
	based on the ranks of the data, called \textbf{Spearman's rank
		correlation}. } \frame{\frametitle{Spearman's rank correlation}
	This is most easily understood through the use of an example. \\ \ \\
	
	Suppose we want to examine the correlation between gestational
	age (GA) and birthweight (BW). {\footnotesize
		\begin{center}
			\begin{tabular}{|l|cccccccc|} \hline
				Infant & 1&2&3&4&5&6&7&8 \\ \hline
				BW (g) &2621&2863&3322&3508&3518&3770&3784&3801 \\
				GA (days) &270&271&267&268&276&282&288&278 \\
				\hline
				BW rank &1&2&3&4&5&6&7&8 \\
				GA rank &3&4&1&2&5&7&8&6 \\ \hline
			\end{tabular}
	\end{center} }
} \frame{\frametitle{Spearman's rank correlation} Spearman's
	rank correlation is based on the squared differences in rank
	for each individual:
	\begin{center}
		\begin{tabular}{|l|cccccccc|} \hline
			Infant & 1&2&3&4&5&6&7&8 \\ \hline
			Rank by BW &1&2&3&4&5&6&7&8 \\
			Rank by GA &3&4&1&2&5&7&8&6 \\ \hline
			Difference &-2&-2&2&2&0&-1&-1&2 \\
			Difference$^2$ &4&4&4&4&0&1&1&4 \\ \hline
		\end{tabular}
	\end{center}
	
	Then Spearman's rank correlation coefficient is computed to be
	\[ r_s = 1- \frac{6\sum d^2}{n^3-n}\]
	
	In our example, this gives $r_s = 0.738$. }

\frame{\frametitle{Spearman's rank correlation} Spearman's rank
	correlation is equivalent to calculating a Pearson's
	correlation on the ranks:
	\[r = \hbox{Corr}(\hbox{Rank}_{\hbox{GA}},\hbox{Rank}_{\hbox{BW}}) = 0.738 \]
}

\frame{\frametitle{Rank correlation: Kendall's $\tau$} There is
	another rank correlation, Kendall's $\tau$, which we will again
	learn by example. \\ \ \\
	
	We study the correlation between gestational age and
	birthweight. {\footnotesize
		\begin{center}
			\begin{tabular}{|l|cccccccc|} \hline
				Infant & 1&2&3&4&5&6&7&8 \\ \hline
				BW (g) &2621&2863&3322&3508&3518&3770&3784&3801 \\
				GA (days) &270&271&267&268&276&282&288&278 \\
				\hline
				BW rank&1&2&3&4&5&6&7&8 \\
				GA rank &3&4&1&2&5&7&8&6 \\ \hline
			\end{tabular}
	\end{center} }
	
} \frame{\frametitle{Rank correlation: Kendall's $\tau$}
	\begin{center}
		\begin{tabular}{|l|cccccccc|} \hline
			Infant & 1&2&3&4&5&6&7&8 \\ \hline
			Rank by b.weight &1&2&3&4&5&6&7&8 \\
			Rank by gest.age &3&4&1&2&5&7&8&6 \\ \hline
		\end{tabular}
	\end{center}
	First, we order the data according to one of the rankings (we
	chose to do so with birthweight).\\ \ \\
	
	Next, we sum the number of infants to the right of each cell
	with a \textbf{higher} ranking for the \textit{other} variable
	(gestational age), and call this $P$:
	\[P = 5+4+5+4+3+1+0=22\]
} \frame{\frametitle{Rank correlation: Kendall's $\tau$}
	
	Then Kendall's rank correlation coefficient is computed to be
	\[ \tau = \frac{2\times P}{\frac{1}{2}n(n-1)}-1\]
	
	In our example, this gives $\tau = 0.57$. \\ \ \\ \ \\ \pause
	
	We can perform hypothesis testing on Kendall's $\tau$; the
	approximately Normal test statistic is \[z = \frac{2\times
		P}{\sqrt{n(n-1)(2n+5)/18}}\] } \frame{\frametitle{Rank
		correlation: Kendall's $\tau$} In our example, if we wish to
	test $H_0: \tau=0$ vs.~$H_A: \tau \ne 0$, this gives
	\begin{eqnarray*}
		z & = & \frac{2\times P}{\sqrt{n(n-1)(2n+5)/18}}\\
		& = & \frac{2\times 22}{\sqrt{8\times7\times21/18}}\\
		& = & 5.444
	\end{eqnarray*}
	which yields a p-value of $P(|Z|>5.444) < 0.001$, indicating
	that there is a statistically significant association as
	measured by Kendall's rank correlation between gestational age
	and birthweight. }

\frame{\frametitle{Rank correlation} \textbf{Notes:}\\
	\begin{itemize}
		\item Both Spearman's and Kendall's correlations lie between
		$-1$ and 1; positive values correspond to a positive association, negative values to a
		negative association. \pause
		\item Both Spearman's and Kendall's correlations are
		nonparametric statistics. \pause
		\item Corrections for ties are required (beyond the scope of this course). \texttt{R} handles it for you.
	\end{itemize}
	
}
			

						
\section{Two categorical variables and contingency tables}
						
\begin{frame}[fragile]{Two categorical variables}
A contingency table summarizes data for two categorical variables:
<<contt-0, echo=TRUE, size = 'scriptsize'>>=
tab1 <- table(famuss$race, 
              famuss$actn3.r577x)
tab1
addmargins(tab1)
@
\end{frame}
					
					
					
					
\begin{frame}[fragile]{Conditional distribution of genotype \textit{given} race}
\begin{figure}
\begin{minipage}[h]{0.30\linewidth}
\small 
			\begin{center}
			The distributions we create this way are called \textbf{\textcolor{blue}{conditional distributions}}, because they show the distribution of one variable for just those cases that satisfy a condition on another variable
			\end{center}

\normalsize
<<contt, echo=TRUE, size = 'tiny'>>=
addmargins(
  prop.table(tab1, margin = 1)
)
@
\end{minipage}
\hspace{0.4cm}
\begin{minipage}[h]{0.59\linewidth}
<<echo=FALSE>>=
#old <- theme_set(theme_minimal())
#theme_set(old)
#theme_update(legend.position = "bottom")
library(cowplot)
sjPlot::set_theme(legend.pos = "bottom", base = theme_minimal_hgrid(font_size = 9))
@

<<genotype-marginals,echo=TRUE, size = "tiny">>=
sjPlot::plot_xtab(famuss$race, 
                  famuss$actn3.r577x,
                  margin = "row")
@
\end{minipage}
\end{figure}
\end{frame}
	
\begin{frame}[fragile]{Conditional distribution of race \textit{given} genotype}

					<<contt44, echo=TRUE, size = 'tiny'>>=
					addmargins(prop.table(tab1, margin = 2))
					@

					<<race-marginals,echo=TRUE, size = "tiny", fig.width = 8, fig.height = 4>>=
					sjPlot::plot_xtab(famuss$race, famuss$actn3.r577x, margin = "col", show.total = F, show.n = F)
					@

\end{frame}

\begin{frame}[fragile]{Marginal distributions of race and genotype}
Given a contingency table, the frequency distribution of one of the variables is called its \textcolor{blue}{\textbf{marginal distribution}}.

<<echo = TRUE, fig.subcap = c('',''), out.width="0.45\\linewidth">>=
table(famuss$race) / nrow(famuss)
sjPlot::plot_frq(famuss$race)
sjPlot::plot_frq(famuss$actn3.r577x)
@

\end{frame}



\begin{frame}{Mosaic plots}
%	\small
\begin{itemize}
	\item A mosaic plot is a graphical display that allows you to examine the relationship among two or more categorical variables.
	\item The mosaic plot starts as a square with length one. The square is divided first into horizontal bars whose widths are proportional to the probabilities associated with the first categorical variable. 
	\item Then each bar is split vertically into bars that are proportional to the conditional probabilities of the second categorical
	variable. Additional splits can be made if wanted using a third, fourth variable, etc.
\end{itemize}

\end{frame}

\begin{frame}[fragile]{Mosaic plots - race and genotype}
	
<<echo=FALSE>>=
old <- theme_set(theme_minimal(base_size = 16L))
theme_set(old)
@	
	
<<mosaic-1,echo = TRUE,fig.asp = 0.681>>=
# devtools::install_github("haleyjeppson/ggmosaic")
pacman::p_load(ggmosaic)
ggplot(data = famuss) +
  geom_mosaic(aes(x = product(race, actn3.r577x),
                  fill = race))
@
	
\end{frame}



\begin{frame}[fragile]{Mosaic plots - race, genotype and sex}
	<<mosaic-2,echo = TRUE,fig.asp = 0.681>>=
    ggplot(data = famuss) +
      geom_mosaic(aes(x = product(race, actn3.r577x),
                      fill = race, conds = product(sex)),
                      divider = mosaic("v"))
	@
	
\end{frame}



\section{A numerical variable and a categorical variable}

\begin{frame}{A numerical variable and a categorical variable}
	\protect\hypertarget{a-numerical-variable-and-a-categorical-variable}{}
	
	\begin{itemize}
		\item \emph{FAMuSS} was designed to study the relationship between genotype at
	the location \emph{r577x} in the gene \emph{ACTN3} and muscle strength.
	
	\item Muscle strength was assessed by the percent change in non-dominant arm
	strength after resistance training (\texttt{ndrm.ch}).
	
	\item What visualization would be a good choice to make this comparison?
	\end{itemize}
	
\end{frame}


\begin{frame}[fragile]{A numerical variable and a categorical variable}
	\protect\hypertarget{a-numerical-variable-and-a-categorical-variable-1}{}
	
	\scriptsize
	
	\scriptsize
	
	<<echo=FALSE>>=
	old <- theme_set(theme_minimal(base_size = 16L))
	theme_set(old)
	@
	
	<<box-1, echo=TRUE, size = 'scriptsize',fig.asp = 0.681>>=
	ggplot(data = famuss, mapping = aes(x = actn3.r577x, y = ndrm.ch, fill = actn3.r577x)) + 
	  geom_boxplot()
	@	
	
	
	\normalsize
	
\end{frame}


\begin{frame}[fragile]{Correlations}
	<<echo=TRUE, error=TRUE, size = "scriptsize">>=
	cor(famuss$actn3.r577x, famuss$ndrm.ch)
	cor(as.numeric(famuss$actn3.r577x), famuss$ndrm.ch, method = "pearson")
	cor(as.numeric(famuss$actn3.r577x), famuss$ndrm.ch, method = "kendall")
	cor(as.numeric(famuss$actn3.r577x), famuss$ndrm.ch, method = "spearman")
	@
\end{frame}

\section{Summary}

\begin{frame}{Summary of exploring data slides} 
	
\begin{itemize}
	\item Two types of variables:
	\begin{itemize}
		\item \textbf{Numeric}: Discrete, Continuous
		\item \textbf{Categorical}: Ordinal, Nominal
	\end{itemize}
\pause
\item The collection of values for a numerical or categorical is called the distribution of that variable
\pause
\item Measures of center include mean and median. 
\item Measures of spread include standard deviation, interquartile range
\item Median and IQR are robust to outliers
\pause
\item Histograms, boxplots, violin plots, and scatterplots are useful graphical summaries of numerical data, which can also be grouped by a categorical variable
\item Bar plots, contingency tables, mosaic plots are useful summaries of categorical data
\end{itemize}
\end{frame}

\begin{frame}{Summary of exploring data slides \textit{continued}} 
	
	\begin{itemize}
		\item Correlation coefficient ($r$) quantifies the strength of a linear trend. 
		\item The \texttt{multiple R-squared} in a simple linear regression output is equal to $r^2$. 
		\item Transformation (e.g. log) can produce better linear associations for highly skewed data. But be careful about the interpretation!
		\pause
		\item Given a contingency table, the frequency distribution of one of the variables is called its marginal distribution
		\item Conditional distributions show the distribution of one variable for just those cases that satisfy a condition on another variable
		\item See \url{https://www.r-graph-gallery.com/} and \url{https://www.data-to-viz.com/} for a collection of graphical displays
	\end{itemize}
\end{frame}

\begin{frame}[fragile]{Session Info}
	\tiny
	
	<<echo=FALSE, comment = NA, size = 'tiny'>>=
	print(sessionInfo(), locale = FALSE)
	@
	
\end{frame}

\end{document}	
	
\hypertarget{case-study-molecular-cancer-classification}{%
\section{Case study: molecular cancer classification}\label{case-study-molecular-cancer-classification}}
						
\begin{frame}{The potential value of genomic data in cancer}
							\protect\hypertarget{the-potential-value-of-genomic-data-in-cancer}{}
							
							The majority of cancers are diagnosed by an expert pathologist examining
							slides of malignant cells.
							
							Can that be done more accurately by characterizing the genetic makeup of
							the malignancy?
							
							\begin{itemize}
								\tightlist
								\item
								This is perhaps the major potential of genomic characterizations of
								tumors.
							\end{itemize}
							
							There are many forms of childhood leukemia.
							
							\begin{itemize}
								\item
								Acute myeloblastic leukemia (AML) and acute lymphoblastic leukemia
								(ALL) are the most common.
								\item
								AML is a cancer of the bone marrow, where white blood cells
								(lymphocytes) are produced.
								\item
								ALL is a cancer of the lymphocytes and is designated as B-cell (ALLB)
								or T-cell (ALLT).
							\end{itemize}
							
\end{frame}


		
\begin{frame}{Prognosis of the two cancers}
							\protect\hypertarget{prognosis-of-the-two-cancers}{}
							
							The probability that a child diagnosed with ALL is survives at least 5
							years after the diagnosis is approximately 90\%.
							
							Approximately 65\% of children diagnosed with AML survive at least 5
							years.
							
							The diagnosis of leukemia type determines the therapy that will be given
							to the child, and the successful treatments for ALL and AML are
							different.
							
							In 1999, Todd Golub from the Dana-Farber and the Broad Institute
							examined the possibility of classifying leukemia through using a genetic
							analysis of a blood sample.
							
						\end{frame}
						
						\begin{frame}{Analyzing the Golub data}
							\protect\hypertarget{analyzing-the-golub-data}{}
							
							We can re-analyze the Golub data using tools from graphical and
							numerical summaries.
							
							Our analysis will not be identical to the Golub analysis, but will be
							similar in spirit.
							
							The tools are straighforward\ldots   
							
							\begin{itemize}
								\item
								Thinking through the problem and assembling the tools is the hard
								part.
								\item
								The process is more important than the final recipe.
							\end{itemize}
							
						\end{frame}
						
						\begin{frame}{Gene expression (details in \emph{OI Biostat})}
							\protect\hypertarget{gene-expression-details-in-oi-biostat}{}
							
							\small
							
							\begin{itemize}
								\item
								The genetic code stored in DNA contains the information for producing
								the proteins that determine an organism's phenotype.
								\item
								Genes that are transcriptionally active (i.e.~turned ``on'') are
								transcribed into messenger RNA (mRNA) that gets translated into
								proteins.
								\item
								Genes can be switched on or off, and expressed at varying levels.
								Variations in gene expression produce the range of physical,
								biochemical, and developmental differences in cells and tissues.
								\item
								Quantifying the amount of RNA produced in a cell allows for a measure
								of gene expression.
								\item
								The transcriptome, or expression profile, is the complete set of RNA
								transcripts produced by the genome in a cell or set of cells.
							\end{itemize}
							
						\end{frame}
						
						\begin{frame}{Microarrays (details in \emph{OI Biostat})}
							\protect\hypertarget{microarrays-details-in-oi-biostat}{}
							
							\small
							
							\begin{itemize}
								\item
								Microarray technology is based on hybridization between two DNA
								strands, in which complementary nucleotide sequences specifically pair
								together.
								\item
								The mRNA from a sample is converted into complementary-DNA (cDNA),
								labeled with a fluorescent dye, and added to the microarray.
								\item
								When cDNA from the sample encounters complementary DNA probes, the two
								strands will hybridize, allowing the cDNA to adhere to specific spots
								on the slide.
								\item
								When the chip is illuminated and scanned, the intensity of
								fluorescence detected at each spot corresponds to the amount of bound
								cDNA.
								\item
								DNA microarrays do not directly quantify gene expression levels or
								quantity of mRNA present in a sample.
								\item
								The fluorescence intensity data only provide a relative measure of
								gene expression, showing which genes on the chip seem to be more or
								less active in relation to each other.
							\end{itemize}
							
						\end{frame}
						
						\begin{frame}{Microarrays}
							\protect\hypertarget{microarrays}{}
							
							\begin{figure}
								\centering
								\includegraphics[scale=0.5]{figures/microarray_schematic.jpg}
								\caption{fluorescence detection}
							\end{figure}
							
						\end{frame}
						
						\begin{frame}{The Golub clinical data}
							\protect\hypertarget{the-golub-clinical-data}{}
							
							Demographic variables described in \emph{OI Biostat} Table 1.54:
							
							\scriptsize
							
							\begin{longtable}[]{@{}ll@{}}
								\toprule
								\begin{minipage}[b]{0.12\columnwidth}\raggedright
									Variable\strut
								\end{minipage} & \begin{minipage}[b]{0.82\columnwidth}\raggedright
									Description\strut
								\end{minipage}\tabularnewline
								\midrule
								\endhead
								\begin{minipage}[t]{0.12\columnwidth}\raggedright
									Samples\strut
								\end{minipage} & \begin{minipage}[t]{0.82\columnwidth}\raggedright
									Sample or chip number. The material from each patient was examined on a
									separate chip and experimental run.\strut
								\end{minipage}\tabularnewline
								\begin{minipage}[t]{0.12\columnwidth}\raggedright
									BM.PB\strut
								\end{minipage} & \begin{minipage}[t]{0.82\columnwidth}\raggedright
									Type of patient material. BM denotes bone marrow; PB denotes a
									peripheral blood sample.\strut
								\end{minipage}\tabularnewline
								\begin{minipage}[t]{0.12\columnwidth}\raggedright
									Gender\strut
								\end{minipage} & \begin{minipage}[t]{0.82\columnwidth}\raggedright
									F for female, M for male.\strut
								\end{minipage}\tabularnewline
								\begin{minipage}[t]{0.12\columnwidth}\raggedright
									Source\strut
								\end{minipage} & \begin{minipage}[t]{0.82\columnwidth}\raggedright
									Hospital where the patient was treated.\strut
								\end{minipage}\tabularnewline
								\begin{minipage}[t]{0.12\columnwidth}\raggedright
									tissue.mf\strut
								\end{minipage} & \begin{minipage}[t]{0.82\columnwidth}\raggedright
									A variable showing the combination of type of patient material and sex
									of the patient. BM:f denotes bone marrow from a female patient,
									etc.\strut
								\end{minipage}\tabularnewline
								\begin{minipage}[t]{0.12\columnwidth}\raggedright
									cancer\strut
								\end{minipage} & \begin{minipage}[t]{0.82\columnwidth}\raggedright
									The type of leukemia; aml is acute myeloblastic leukemia, allB is acute
									lymphoblastic leukemia which started in B-cells (cells that mature into
									plasma cells) origin, and allT is acute lymphoblastic leukemia with
									T-cell origin (T-cells are a type of white blood cell).\strut
								\end{minipage}\tabularnewline
								\bottomrule
							\end{longtable}
							
						\end{frame}
						
						\begin{frame}{The Golub expression data}
							\protect\hypertarget{the-golub-expression-data}{}
							
							The expression data is contained in the last 7,129 columns.
							
							Each column is a variable with a name corresponding to the name of the
							probe on the microarray.
							
							The expression levels record fluorescence intensity for each gene.
							
							\begin{itemize}
								\item
								The intensity levels have no inherent biological meaning.
								\item
								Data have been normalized to adjust for variability between the
								separate arrays used for each patient.
							\end{itemize}
							
						\end{frame}
						
						\begin{frame}{Selected variables and columns from Golub data}
							\protect\hypertarget{selected-variables-and-columns-from-golub-data}{}
							
							\captionsetup[table]{labelformat=empty}
							\scriptsize
							
							\scriptsize
							
							\begin{longtable}[]{@{}rllrrr@{}}
								\caption{\emph{OI Biostat} Table 1.40}\tabularnewline
								\toprule
								Samples & Gender & cancer & AFFX-BioB-5\_at & AFFX-BioB-M\_at &
								AFFX-BioB-3\_at\tabularnewline
								\midrule
								\endfirsthead
								\toprule
								Samples & Gender & cancer & AFFX-BioB-5\_at & AFFX-BioB-M\_at &
								AFFX-BioB-3\_at\tabularnewline
								\midrule
								\endhead
								39 & F & allB & -1363.28 & -1058.59 & -541.47\tabularnewline
								40 & F & allB & -796.29 & -1167.10 & 7.54\tabularnewline
								42 & F & allB & -679.14 & -1069.83 & -690.30\tabularnewline
								47 & M & allB & -1164.40 & -1109.94 & -990.13\tabularnewline
								48 & F & allB & -1299.65 & -1402.00 & -1077.54\tabularnewline
								\bottomrule
							\end{longtable}
							
							\normalsize
							
						\end{frame}
						
						\begin{frame}{Analyzing the Golub leukemia data}
							\protect\hypertarget{analyzing-the-golub-leukemia-data}{}
							
							We will do an analysis in class using some of the simple but
							surprisingly powerful ideas behind numerical and graphical summaries.
							
							The goal of the Golub study was to develop a procedure for
							distinguishing between AML and ALL based only on the gene expression
							levels of a patient. There are two major issues to be addressed:
							
							\begin{enumerate}
								\item
								Which genes are the most informative for making a prediction?
								\item
								What is a workable strategy for predicting leukemia type from
								expression data for a specific set of genes?
							\end{enumerate}
							
						\end{frame}
						
						\begin{frame}[fragile]{Starting small\ldots{}}
							\protect\hypertarget{starting-small}{}
							
							\footnotesize
							
							\scriptsize
							
\begin{verbatim}
##    cancer        A         B        C        D
## 69   allB 39307.96 35232.401 41170.76 35792.79
## 67   allT 32281.88 41432.024 59328.51 49608.14
## 55   allB 47429.94 35568.928 56074.96 42857.78
## 56   allB 25533.87 16983.749 28056.75 32693.92
## 59   allB 35960.55 24191.746 27637.90 22240.75
## 52    aml 46177.95  6189.465 12557.24 34485.41
## 53    aml 43790.70 33661.825 38380.30 29758.25
## 51    aml 53420.05 26109.245 31427.20 23809.70
## 50    aml 41241.59 37589.773 47325.77 30099.36
## 54    aml 41300.57 49198.412 66026.10 56248.62
\end{verbatim}
\end{frame}
						



%\begin{frame}[allowframebreaks]
%\nocite{breiman1984classification}
%	\nocite{friedman2001elements}
%	\nocite{james2013introduction}
%	\nocite{lopez2015arbres}
%	\frametitle{References}
%\printbibliography
%\end{frame}




\end{document}

---
title: Lab 005 - Inference for means - Solutions
author:
  - name: EPIB607 - Inferential Statistics
    affiliation: a
#  - name: Second Author
#    affiliation: a,b
address:
  - code: a
    address: McGill University
#  - code: b
#    address: Department of Neat Tricks, Whereever State University, Someplace, MC, 67890
lead_author_surname: Bhatnagar and Hanley
doi: "https://sahirbhatnagar.com/EPIB607/"
abstract: |
  In this exercise you will practice calculating confidence intervals using the t-distribution and the bootstrap.
# Optional: Acknowledgements
#acknowledgements: |
#  [rticles](https://cran.r-project.org/package=rticles) package, and both packages rely on the
#  [PNAS LaTeX](http://www.pnas.org/site/authors/latex.xhtml) macros. Both these sources are
#  ([GPL-3](https://www.gnu.org/licenses/gpl-3.0.en.html) and
#  [LPPL (>= 1.3)](https://www.latex-project.org/lppl/)).
# Optional: One or more keywords
keywords:
  - Sampling distribution
  - Standard error
  - Normal distribution
  - Quantiles
  - Percentiles
  - Z-scores
papersize: letter
fontsize: 11pt
# Optional: Force one-column layout, default is two-column
one_column: true
# Optional: Enables lineno mode, but only if one_column mode is also true
#lineno: true
# Optional: Enable one-sided layout, default is two-sided
#one_sided: true
# Optional: Enable section numbering, default is unnumbered
numbersections: true
# Optional: Specify the depth of section number, default is 5
#secnumdepth: 5
# Optional: Skip inserting final break between acknowledgements, default is false
skip_final_break: true
# Optional: Bibliography 
bibliography: pinp
# Optional: Enable a 'Draft' watermark on the document
watermark: false
footer_contents: "Lab 005"
output: pinp::pinp
# Required: Vignette metadata for inclusion in a package.
vignette: >
  %\VignetteIndexEntry{YourPackage-vignetteentry}
  %\VignetteKeywords{YourPackage, r, anotherkeyword}
  %\VignettePackage{Due Sepetember 28, 2018}
  %\VignetteEngine{knitr::rmarkdown}
editor_options: 
  chunk_output_type: console
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(message = FALSE, warning = FALSE, fig.width = 6, fig.height = 6)
library(dplyr)
library(knitr)
library(kableExtra)
library(mosaic)
library(tidyr)
```


|R Code                     |       Value        |
|:--------------------------|:----------------------------------|
|`qnorm(p = c(0.05, 0.95))` |`r round(qnorm(p = c(0.05, 0.95)), 2)`    |
|`qnorm(p = c(0.025, 0.975))` |`r round(qnorm(p = c(0.025, 0.975)),2)`    |
|`qnorm(p = c(0.005, 0.995))` |`r round(qnorm(p = c(0.005, 0.995)),2)`    |
|`qt(p = c(0.025, 0.975), df = 400-1)` |`r round(qt(p = c(0.025, 0.975), df = 400-1), 2)`    |
|`qt(p = c(0.025, 0.975), df = 25-1)` |`r round(qt(p = c(0.025, 0.975), df = 25-1), 2)`    |
|`qt(p = c(0.025, 0.975), df = 20-1)` |`r round(qt(p = c(0.025, 0.975), df = 20-1), 2)`    |
|`qt(p = c(0.025, 0.975), df = 16-1)` |`r round(qt(p = c(0.025, 0.975), df = 16-1), 2)`    |



# Food intake and weight gain

If we increase our food intake, we generally gain weight. Nutrition scientists can calculate the amount of weight gain that would be associated with a given increase in calories. In one study, 16 nonobese adults, aged 25 to 36 years, were fed 1000 calories per day in excess of the calories needed to maintain a stable body weight. The subjects maintained this diet for 8 weeks, so they consumed a total of 56,000 extra calories. According to theory, 3500 extra calories will translate into a weight gain of 1 pound. Therfore we expect each of these subjects to gain 56,000/3500=16 pounds (lb). Here are the weights (given in the `weightgain.csv` file) before and after the 8-week period expressed in kilograms (kg):

```{r, eval=FALSE, echo=TRUE}
weight <- read.csv("weightgain.csv")
```

<br>

a. Calculate a 95% confidence interval for the mean weight change and give a sentence explaining the meaning of the 95%. State your assumptions. 

```{r, echo=TRUE, eval=TRUE}
weight <- read.csv("~/git_repositories/epib607/inst/labs/005-one-sample-mean/weightgain.csv")

# Creating new variable for weight change
weight$change <- weight$after-weight$before
weight$change_lb <- weight$change*2.2

# Calculating the mean of weight change and rounding
(ybar_change <- mean(weight$change))

# Calculating the sample standard deviation
(ssd_change <- sd(weight$change))

# sample size
(n <- nrow(weight))

# Calculating a 95% confidence interval version 1
qt_scaled <- function(p, df, mean, sd) {
  mean  + qt(p = p, df = df) * sd
}

(q1_ci95 <- qt_scaled(p = c(0.025, 0.975), 
                     df = nrow(weight) - 1, 
                     mean = ybar_change, 
                     sd = ssd_change / sqrt(n)))


# Calculating a 95% confidence interval version 2
ybar_change +  qt(p = c(0.025, 0.975), df = n - 1) * ssd_change / sqrt(n)

```


The 95% confidence interval for the mean weight change is `r round(ybar_change,2)` kg (`r round(q1_ci95[1],2)` kg, `r round(q1_ci95[2],2)` kg). If the method used in this study were repeated many times, 95% of the time, the interval `r round(q1_ci95[1],2)` kg and `r round(q1_ci95[2],2)` kg will cover the true mean weight change. We can also say that we are 95% confident that the population mean weight gain is between (`r round(q1_ci95[1],2)` kg, `r round(q1_ci95[2],2)` kg). Remember that the our uncertainty is about whether the particular sample we have at hand is one of the successful ones or one of the 5% that fail to produce an interval that captures the true value.


As this confidence interval was calculated using the *t* procedure, we are assuming that (1) we can regard our data as a simple random sample (SRS) from the population, (2) we have a representative sample of the population weight change and (3) observations of weight change in the population have a Normal distribution because we don't believe the CLT has kicked in. 

b. Calculate a 95% bootstrap confidence interval for the mean weight change and compare it to the one obtained in part (a). Comment on the bootstrap sampling distribution and compare it to the assumptions you made in part (a).

```{r, echo=TRUE, eval=TRUE, fig.asp=0.681}
q1_dist <- replicate(1000, expr = {
  dplyr::sample_n(weight, size = n, replace = TRUE) %>%
    dplyr::summarize(r = mean(change)) %>%
    dplyr::pull(r)
})
hist(q1_dist, col = "lightblue", lwd = 2)
round(quantile(q1_dist, probs = c(0.001, 0.005, .025, 0.05, 
                                                 0.90, 0.95, 0.975, 0.99)),2)
```

The 95% Bootstrap interval is given by [`r round(quantile(q1_dist, probs = c(.025, 0.975)),2)`] kg. Very similar to the interval given in part a). Gives us some more confidence that the CLT has indeed kicked in. 


c. Convert the units of the mean weight gain and 95% confidence interval to pounds. Note that 1 kilogram is equal to 2.2 pounds. Test the null hypothesis that the mean weight gain is 16 lbs. State your assumptions and justify your choice of test. Be sure to specify the null and alternative hypotheses. What do you conclude?
We convert the Bootsrap CI by simply multiplying the upper and lower limits by 2.2lbs to give:

```{r, echo=TRUE, eval=TRUE, fig.asp=0.681}
quantile(q1_dist, probs = c(.025, 0.975)) * 2.2
```

The null hypothesis is that the theory of weight gain is the same as the measured weigth gain, $H_0: \mu = \mu_o = 16$ lbs, and the alternative hypothesis is $H_a: \mu \neq 16$ lbs (two tailed test). I want to test it using the bootstrap method beacause I don't want to assume that the CLT has kicked in and the sampling distribution is normal. Since the upper limit of the confidence interval is below 16 lbs, there is evidence to suggest that we should reject the null hypothesis, i.e., the actual weight gain might be lower than the theory says. 


\newpage

# Attitudes toward school

The Survey of Study Habits and Attitudes (SSHA) is a psychological test that measures the motivation, attitude toward school, and study habits of students. Scores range from 0 to 200. The mean score for U.S. college students is about 115, and the standard deviation is about 30. A teacher who suspects that older students have better attitudes toward school gives the SSHA to 25 students who are at least 30 years of age. Their mean score is $\bar{y}$ = 132.2 with a sample standard deviation $s = 28$. 

a. The teacher asks you to carry out a formal statistical test for her hypothesis. Perform a test, provide a 95% confidence interval and state your conclusion clearly. 

## Using the t procedure

```{r, results='hide', fig.keep='none'}
qt_scaled(p = c(0.025, 0.975), df = 24, mean = 132.2, sd = 28/sqrt(25))

# alternatively
132.2 + qt(p = c(0.025, 0.975), df = 24) * 28 / sqrt(25)
```


The null hypothesis is that older student mean SSHA score equals all student mean SSHA scores, $H_0: \mu = \mu_0 = 115$. The alternate hypothesis is that older student mean SSHA score is greater than 115, $H_a: \mu > 115$ (ie: one-tail test). The sample size is on the smaller side (ie: below 30), so I chose to use a one sample t-test because I don't trust the sample sd to be a good estimate of the population sd. A two tailed 95% CI is [`r round(qt_scaled(p = c(0.025, 0.975), df = 24, mean = 132.2, sd = 28/sqrt(25)),2)`]. Based on this, I reject the null hypothesis, .i.e. , our data provides evidence that there might be a difference in SSHA scores between older students and the general population of students. 


## Using the z procedure

```{r, echo=TRUE}
qnorm(p = c(0.025, 0.975), mean = 132.2, sd = 30/sqrt(25))

# alternatively
132.2 + qnorm(p = c(0.025, 0.975)) * 30/sqrt(25)
```


Assuming that the standard deviation of the all U.S. college students of 30 is accurate and taken as sigma, the 95% confidence interval for the population mean SSHA score is [`r round(qnorm(p = c(0.025, 0.975), mean = 132.2, sd = 30/sqrt(25)),2)`]. 


b. What assumptions did you use in part (a). Which of these assumptions is most important to the validity of your conclusion in part (a).

We are assuming that this is a simple random sample of older students. If using the $t$-distribution, we are assuming that the standard deviation of the population is not a good estimate of the standard deviation of our sample. The most important assumption we've made is that the CLT has kicked in and therefore the sampling distribution is normal. 

If using $z$ procedure $\to$ that the standard deviation of the all U.S. college students of 30 is accurate and taken as sigma, and that the sample size is enough that the CLT has kicked in. 


# Does a full moon affect behavior?

Many people believe that the moon influences the actions of some individuals. A study of dementia patients in nursing homes recorded various types of disruptive behaviors every day for 12 weeks. Days were classified as moon days if they were in a 3-day period centered at the day of the full moon. For each patient, the average number of disruptive behaviors was computed for moon days and for all other days. The hypothesis is that moon days will lead to more disruptive behavior. We look at a data set consisting of observations on 15 dementia patients in nursing homes (available in the `fullmoon.csv` file): 

```{r, echo=TRUE, eval=FALSE}
fullmoon <- read.csv("fullmoon.csv")
```

```{r, eval=TRUE, echo=FALSE}
# moon <- load("~/Downloads/FullMoon.RData")
# FullMoon$aggdiff <- NULL
# colnames(FullMoon) <- c("patient","moon_days", "other_days")
# write.csv(FullMoon, file = "fullmoon.csv", quote = FALSE, row.names = FALSE)
fullmoon <- read.csv("~/git_repositories/epib607/inst/labs/005-one-sample-mean/fullmoon.csv")
fullmoon

moon.diff <- fullmoon$moon_days - fullmoon$other_days

moon.mean <- mean(moon.diff)
moon.sdev <- sd(moon.diff)
moon.n <- length(moon.diff)

t95.moon <- qt(0.975, df = moon.n-1)

moon.error <- t95.moon*moon.sdev/sqrt(moon.n)

CI95.moon.t <- moon.mean + c(-moon.error, moon.error)

#fullmoon$diff <- fullmoon$moon_days - fullmoon$other_days
# s_dist <- do(10000) * mean(~ diff, data = resample(fullmoon))
# hist(s_dist$mean)
# knitr::kable(fullmoon)
```

a. Calculate a 95% confidence interval for the mean difference in disruptive behaviors. State the assumptions you used to calculate this interval.

```{r, echo=TRUE, eval=TRUE}
(moon.mean <- mean(moon.diff))
(moon.sdev <- sd(moon.diff))
(moon.n <- length(moon.diff))

qt_scaled(p=c(0.025, 0.975), df = moon.n - 1, mean = moon.mean, sd = moon.sdev/sqrt(moon.n))

# alternatively
moon.mean + qt(p = c(0.025, 0.975), df = moon.n - 1) * moon.sdev/sqrt(moon.n)
```

Assuming a simple random sample and that our sample is representative of the population, and that the difference in distruptive events is normally distributed in the population  (OR you can say that you believe the Central Limit Theorem (CLT) has kicked in), I calculated a 95% confidence interval for the population mean difference of [`r round(qt_scaled(p=c(0.025, 0.975), df = moon.n - 1, mean = moon.mean, sd = moon.sdev/sqrt(moon.n)), 2)` distruptive events on full moon days when compared to other days. This was done using the $t$ procedure due to the unknown sigma and small sample size of n = 15.

b. Test the hypothesis that moon days will lead to more disruptive behavior. State your assumptions and provide a brief conclusion based on your analysis. 

```{r, echo=TRUE}
#t-statistic
(t_statistic <- (moon.mean - 0) / (moon.sdev/sqrt(moon.n)))

# p-value
pt(q = t_statistic, df = moon.n-1, lower.tail = F)
```

$H_0: \mu = 0$ (i.e. that there is no difference in distruptive behaviours on full moon nights when compared to other nights) and $H_a: \mu > 0$ (i.e. that there are more distruptive behaviours on full moon nights when compared to other nights). 

I calculate a one-sided (to the right) p-value using the $t$ statistic (because unknown sigma and small sample size of n = 15) of `r pt(q = t_statistic, df = moon.n-1, lower.tail = F)`. Assuming the null hyposthesis is true, there is very small probability that the observed mean difference of `r moon.mean` came from the null distribution. We could also say that since $\mu = 0$ is not contained within our 95% confidence interval, this provides evidence against the null hypothesis. This is based on the assumptions that the sample distribution here is enough that the CLT has kicked in as well.

c. Find the minimum value of the mean difference in disruptive behaviors ($\bar{y}$) needed to reject the null hypothesis. 

We first need to figure out for what values we can reject the null. Since this is a one-sided alternative we want and $\alpha=0.05$ in the right tail. The cutoff is then given by:
```{r, echo=TRUE}
(tscore.null <- qt(p = 0.95, df = 15-1))
```

Then we solve for $\bar{y}$ in the $t$-statistic formula:

\begin{align*}
t_{statistic} & = \frac{\bar{y} - \mu_0}{s/\sqrt{n}} \\
1.76 & = \frac{\bar{y} - 0}{1.46/\sqrt{15}}
\end{align*}

The solution to the above equation is:
```{r, echo=TRUE}
tscore.null*(moon.sdev/sqrt(moon.n))
```

Assuming $H_0$ is true, under the null distribution the minimum value in mean difference in distruptive behaviours needed to reject the null hypothesis at an $\alpha=0.05$ level is `r round(tscore.null*(moon.sdev/sqrt(moon.n)), 2)` distruptive behaviours.

d. What is the probability of detecting an increase of 1.0 aggressive behavior per day during moon days? 

$$
H_0: \mu = 0 \qquad \qquad H_A: \mu > 1
$$
This is a standard power calculation. In the first step, we calculate the difference in mean disruptive behaviours needed to reject the null hypothesis, which we calculated in part c) to be `r round(tscore.null*(moon.sdev/sqrt(moon.n)), 2)`. The corresponding $t$ value under the alternative hypothesis distribution is given by

\begin{align*}
t_{statistic} & = \frac{\bar{y} - \mu_A}{s/\sqrt{n}} \\
 & = \frac{0.664 - 1}{1.46/\sqrt{15}} \\
 & = -0.890
\end{align*}

```{r, eval=FALSE, echo=FALSE}
(tscore.null*(moon.sdev/sqrt(moon.n)) - 1) / (moon.sdev/sqrt(moon.n))
```

We then calculate the probability of observing this value or more under the alternative hypothesis distribution:

```{r, echo=TRUE}
pt(q = -0.890, df = moon.n - 1, lower.tail = FALSE)
```

Therefore, the power to detect an increase of 1.0 aggressive behavior per day during moon days is `r round(pt(q = -0.890, df = moon.n - 1, lower.tail = FALSE)*100, 2)`%.




